{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293af73d-dac2-4969-af4e-5f7dd76a5909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T01:47:15.236438Z",
     "iopub.status.busy": "2023-04-09T01:47:15.236062Z",
     "iopub.status.idle": "2023-04-09T01:47:24.456346Z",
     "shell.execute_reply": "2023-04-09T01:47:24.455758Z",
     "shell.execute_reply.started": "2023-04-09T01:47:15.236367Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.3.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/saturn/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.11.0 huggingface-hub-0.13.4 regex-2023.3.23 tokenizers-0.13.3 transformers-4.27.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce0de10-2aee-4e4e-b4f8-0b9b30ac8890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T01:47:24.458460Z",
     "iopub.status.busy": "2023-04-09T01:47:24.458006Z",
     "iopub.status.idle": "2023-04-09T01:47:27.405446Z",
     "shell.execute_reply": "2023-04-09T01:47:27.404566Z",
     "shell.execute_reply.started": "2023-04-09T01:47:24.458422Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3923adca-d4e0-4a2f-9315-5b49048712e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T01:47:27.407082Z",
     "iopub.status.busy": "2023-04-09T01:47:27.406853Z",
     "iopub.status.idle": "2023-04-09T01:47:27.416559Z",
     "shell.execute_reply": "2023-04-09T01:47:27.415820Z",
     "shell.execute_reply.started": "2023-04-09T01:47:27.407056Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2252554173.py, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    no_repeat_ngram_size=,\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "df = pd.read_csv(\"Train_Only_Sentence_Title.csv\", encoding='utf-8-sig', sep=';')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "summaries = []\n",
    "for article_text in tqdm(df[\"generated_text\"]):\n",
    "    input_ids = tokenizer(\n",
    "        [WHITESPACE_HANDLER(article_text)],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )[\"input_ids\"].to(device)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=84,\n",
    "        no_repeat_ngram_size=4,\n",
    "        num_beams=2\n",
    "    )[0]\n",
    "\n",
    "    summary = tokenizer.decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    summaries.append(summary)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "df[\"summary\"] = summaries\n",
    "df.to_csv(\"Train_Only_Sentence_Title_out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d754980-a519-4c5c-8669-c0a2e1d514b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
