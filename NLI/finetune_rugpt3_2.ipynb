{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/totminaekaterina/RUSSE-2022-Detoxification/blob/main/finetune_rugpt3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "deWiwhTdthln",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AutoTokenizer,\n\u001b[0;32m     11\u001b[0m                           AutoModelForCausalLM,\n\u001b[0;32m     12\u001b[0m                           Trainer,\n\u001b[0;32m     13\u001b[0m                           TrainingArguments,\n\u001b[0;32m     14\u001b[0m                           TrainerCallback,\n\u001b[0;32m     15\u001b[0m                           AdamW,\n\u001b[0;32m     16\u001b[0m                           get_linear_schedule_with_warmup)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\__init__.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     33\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     logging,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     48\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\dependency_versions_check.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pkg \u001b[38;5;129;01min\u001b[39;00m deps:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pkg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# must be loaded here, or else tqdm check may fail\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_tokenizers_available\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tokenizers_available():\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\__init__.py:34\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     28\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     ContextManagers,\n\u001b[0;32m     36\u001b[0m     ExplicitEnum,\n\u001b[0;32m     37\u001b[0m     ModelOutput,\n\u001b[0;32m     38\u001b[0m     PaddingStrategy,\n\u001b[0;32m     39\u001b[0m     TensorType,\n\u001b[0;32m     40\u001b[0m     cached_property,\n\u001b[0;32m     41\u001b[0m     expand_dims,\n\u001b[0;32m     42\u001b[0m     find_labels,\n\u001b[0;32m     43\u001b[0m     flatten_dict,\n\u001b[0;32m     44\u001b[0m     is_jax_tensor,\n\u001b[0;32m     45\u001b[0m     is_numpy_array,\n\u001b[0;32m     46\u001b[0m     is_tensor,\n\u001b[0;32m     47\u001b[0m     is_tf_tensor,\n\u001b[0;32m     48\u001b[0m     is_torch_device,\n\u001b[0;32m     49\u001b[0m     is_torch_tensor,\n\u001b[0;32m     50\u001b[0m     reshape,\n\u001b[0;32m     51\u001b[0m     squeeze,\n\u001b[0;32m     52\u001b[0m     tensor_size,\n\u001b[0;32m     53\u001b[0m     to_numpy,\n\u001b[0;32m     54\u001b[0m     to_py_obj,\n\u001b[0;32m     55\u001b[0m     transpose,\n\u001b[0;32m     56\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     59\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     60\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     send_example_telemetry,\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     89\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     90\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m     torch_version,\n\u001b[0;32m    164\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, ContextManager, List, Tuple\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:381\u001b[0m\n\u001b[0;32m    379\u001b[0m _torch_fx_available \u001b[38;5;241m=\u001b[39m _torch_onnx_dict_inputs_support_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_available:\n\u001b[1;32m--> 381\u001b[0m     torch_version \u001b[38;5;241m=\u001b[39m \u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimportlib_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     _torch_fx_available \u001b[38;5;241m=\u001b[39m (torch_version\u001b[38;5;241m.\u001b[39mmajor, torch_version\u001b[38;5;241m.\u001b[39mminor) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    383\u001b[0m         TORCH_FX_REQUIRED_VERSION\u001b[38;5;241m.\u001b[39mmajor,\n\u001b[0;32m    384\u001b[0m         TORCH_FX_REQUIRED_VERSION\u001b[38;5;241m.\u001b[39mminor,\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    387\u001b[0m     _torch_onnx_dict_inputs_support_available \u001b[38;5;241m=\u001b[39m torch_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m TORCH_ONNX_DICT_INPUTS_MINIMUM_VERSION\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\packaging\\version.py:52\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(version)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(version: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124;03m\"\"\"Parse the given version string.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    >>> parse('1.0.dev1')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    :raises InvalidVersion: When the version string is not a valid version.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\packaging\\version.py:195\u001b[0m, in \u001b[0;36mVersion.__init__\u001b[1;34m(self, version)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"Initialize a Version object.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m:param version:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    exception will be raised.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Validate the version and parse it into pieces\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_regex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidVersion(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid version: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          TrainerCallback,\n",
    "                          AdamW,\n",
    "                          get_linear_schedule_with_warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\totmi\\anaconda3\\lib\\site-packages (4.27.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\totmi\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\totmi\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kTFR32WFtmC2"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8OasBIH_tmmC"
   },
   "outputs": [],
   "source": [
    "def get_random_example(dataset):\n",
    "    sample = dataset.sample()\n",
    "    prompt = f'<|startoftext|>{sample[\"sentence1\"].item()}<|sep|>'\n",
    "    true_output = sample[\"sentence2\"].item()\n",
    "    return prompt, true_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gh-ChU7Utrw8"
   },
   "outputs": [],
   "source": [
    "class SimplificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts_list, tokenizer, gpt2_type=\"gpt2\", max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        texts_combined = []\n",
    "        for input_text, out_text in texts_list:\n",
    "            text_combined = f\"<|startoftext|>{input_text}<|sep|>{out_text}<|endoftext|>\"\n",
    "            texts_combined.append(text_combined)\n",
    "        self.encodings = tokenizer(texts_combined,\n",
    "                              truncation=True,\n",
    "                              max_length=max_length,\n",
    "                              padding=\"max_length\",\n",
    "                              return_tensors=\"pt\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"label\"] = item[\"input_ids\"]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D4q5qVXutu6J"
   },
   "outputs": [],
   "source": [
    "class PrintExampleCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, logs=None, **kwargs):\n",
    "        prompt, true_output = get_random_example(valid)\n",
    "        print(prompt.strip(\"<|startoftext|>\").strip(\"<|sep|>\"), true_output, sep=\"\\n\")\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sample_outputs = model.generate(\n",
    "                input_ids,\n",
    "                do_sample=True,   \n",
    "                top_k=50,\n",
    "                max_length=MAX_LENGTH,\n",
    "                top_p=0.95,\n",
    "                temperature=0.9,\n",
    "                num_return_sequences=1\n",
    "            ).detach().cuda()\n",
    "        model.train()\n",
    "\n",
    "        for sample in sample_outputs:\n",
    "            res = (tokenizer.decode(sample, skip_special_tokens=False)\n",
    "                            .split(\"<|sep|>\")[1]\n",
    "                            .replace(\"<|pad|>\", \"\")\n",
    "                            .replace(\"<|endoftext|>\", \"\"))\n",
    "            print(res, \"-\" * 80, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iKduBssgt7ll"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"NLI_train.csv\"\n",
    "VALID_PATH = \"NLI_val.csv\"\n",
    "TEST_PATH = \"NLI_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e7XA3lsuuUnN"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_PATH, encoding='utf-8-sig', sep=';')\n",
    "valid = pd.read_csv(VALID_PATH, encoding='utf-8-sig', sep=';')\n",
    "valid.drop([\"label\"], axis=1, inplace=True)\n",
    "train.drop([\"label\"], axis=1, inplace=True)\n",
    "valid.columns = [\"sentence1\", \"sentence2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В реанимации: измеренные жиз. показатели Т 37....</td>\n",
       "      <td>Пациент гемодинамически нестабилен.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63-летняя женщина с гиперхолестеринемией и язв...</td>\n",
       "      <td>у пациента отстутствует история болезни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ИСТОРИЯ ТЕКУЩЕГО ЗАБОЛЕВАНИЯ: Пациент - мужчин...</td>\n",
       "      <td>у пациента нормальная функция почек</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ИСТОРИЯ: [**Фамилия пациента**] - мальчик 33-6...</td>\n",
       "      <td>пациент доношен</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Отрицал наличие головной боли, тошноты или рвоты.</td>\n",
       "      <td>У него гематемезис</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  В реанимации: измеренные жиз. показатели Т 37....   \n",
       "1  63-летняя женщина с гиперхолестеринемией и язв...   \n",
       "2  ИСТОРИЯ ТЕКУЩЕГО ЗАБОЛЕВАНИЯ: Пациент - мужчин...   \n",
       "3  ИСТОРИЯ: [**Фамилия пациента**] - мальчик 33-6...   \n",
       "4  Отрицал наличие головной боли, тошноты или рвоты.   \n",
       "\n",
       "                                 sentence2  \n",
       "0      Пациент гемодинамически нестабилен.  \n",
       "1  у пациента отстутствует история болезни  \n",
       "2      у пациента нормальная функция почек  \n",
       "3                          пациент доношен  \n",
       "4                       У него гематемезис  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU0T-xbruCjY"
   },
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "4d170125abf94f07a31e70ead0dadf59",
      "686a2b14fd9d454e940e5d3800cd497c",
      "830f2781b53b42e9ae005e1309bdf875",
      "dd404b13dbe54bbcbf89ae8a309f0784",
      "d1ddd6a9b66344338c2b14033886875f",
      "715546484d3f48ef99ee932a9995c7ae",
      "1df8251e9b0f42ee8006d0edb8e27876",
      "f39393a0a3184684a1d6ccee77fbb0e0",
      "64fbf94a197f4292b46f79402b6dd537",
      "6c4bacdf235b445da3fec2f4af486c98",
      "5e1c6e478324407eb3ba4830a87b09d0",
      "1af4bcff1a274d99a2bebcab2db7b39d",
      "f245eb8545b04e2aa0b8f05f9e8a186e",
      "ab026b9949dd44849cdaf7503931a242",
      "c993543ac6d840c8969a1d6e70e10619",
      "deb22e5731ea4939bc8b4d6205dfeeb3",
      "5cd4998b2a924d4c88e427311adc80ec",
      "b1058afa70f849bca2fd261645e34870",
      "fa70a4a687c9496fa0dbe46948064147",
      "a1f71cca96cc4782a2a4809b0e31fc5f",
      "ec8b83b8f7b54203a243317bffe3d4ce",
      "5d6e22f9b2004906b942e9b7529d4c55",
      "8c30aa6d8c4040909875e19afa34ca13",
      "841a4a9a9d0e4596b93487474f1a5af7",
      "bf98ff8cec3543d7a3119b3388dae16d",
      "0a68ea0525934e6198d7bbe9ef964a99",
      "19440dd3382048e5b15c45d3edd3febe",
      "b44842beeec145979d66024ef2ce7467",
      "dd3821046be140efaa3fa0a2ca45566d",
      "2e6ef668f2fb40848fe273d855b85395",
      "2ba00e7067e84581abec04c893f92aaa",
      "461f5fc3cf9e4ae69fa2d594e0d1c126",
      "f929a4fd07d244e9828972588bebc5fe",
      "8f0d951c8da344b78a838943d9608a7b",
      "a7683bb4cdb04c889de19c13a7db3eb6",
      "de2ab6cc76ed4a9c80a4f0a2b5925aa3",
      "da618545d5b94f4ea5499b06670386ca",
      "012dd3257a84424780f8ad59daa5cca4",
      "a280823504154bb7848064b9f244ea7a",
      "df5320f3ea3e4eb9b3e8aeee7982132b",
      "6320330f817b44959762b1bb694315a4",
      "7a49b39f2d23477fb15a46084fea67d5",
      "5e2f12dff1c6483f9468f18cc8b02137",
      "cdf3afd39ca44095a9ed21e65adc9bab"
     ]
    },
    "id": "mti29uEZuFH8",
    "outputId": "e0b858d2-18c1-41f4-d2e0-811af08f99da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qatN9oaJuLKV"
   },
   "source": [
    "# add special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_2fvKZiuMAn",
    "outputId": "3a0e6099-1ec1-4358-aafe-1273846398b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50261, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = {\n",
    "    \"bos_token\": \"<|startoftext|>\",\n",
    "    \"pad_token\": \"<|pad|>\",\n",
    "    \"sep_token\": \"<|sep|>\",\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwsNPfLiNlXj",
    "outputId": "f4023653-36c4-4565-a05d-089be84825e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 3120\n",
      "Evaluate and save every 624 steps.\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 200\n",
    "DATA_COLS = [\"sentence1\", \"sentence2\"]\n",
    "train_dataset = SimplificationDataset(train[DATA_COLS].values.tolist(), tokenizer, max_length=MAX_LENGTH)\n",
    "valid_dataset = SimplificationDataset(valid[DATA_COLS].values.tolist(), tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "EPOCH_STEPS = len(train_dataset) // 8 // 1\n",
    "EVAL_STEPS = EPOCH_STEPS\n",
    "print(f\"Total steps: {EPOCH_STEPS * 5}\\nEvaluate and save every {EVAL_STEPS} steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ywJc24MgHqEF"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"result_rugpt3small_NLI\",\n",
    "    logging_dir=\"logs_rugpt3small_NLI\",\n",
    "    logging_first_step=True,\n",
    "    num_train_epochs=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    save_steps=EVAL_STEPS,\n",
    "    logging_steps=100,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=500,\n",
    "    learning_rate=0.00005,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0,\n",
    "    fp16=False,\n",
    "    seed=19,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kitNkB_au1ok"
   },
   "outputs": [],
   "source": [
    "Path(training_args.output_dir).mkdir(exist_ok=True)\n",
    "Path(training_args.logging_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ojsZqOvvQI5",
    "outputId": "79b783f8-58d4-4498-ecb9-2ac243846011",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adafactor': False,\n",
      " 'adam_beta1': 0.9,\n",
      " 'adam_beta2': 0.999,\n",
      " 'adam_epsilon': 1e-08,\n",
      " 'auto_find_batch_size': False,\n",
      " 'bf16': False,\n",
      " 'bf16_full_eval': False,\n",
      " 'data_seed': None,\n",
      " 'dataloader_drop_last': False,\n",
      " 'dataloader_num_workers': 0,\n",
      " 'dataloader_pin_memory': True,\n",
      " 'ddp_bucket_cap_mb': None,\n",
      " 'ddp_find_unused_parameters': None,\n",
      " 'ddp_timeout': 1800,\n",
      " 'debug': [],\n",
      " 'deepspeed': None,\n",
      " 'disable_tqdm': False,\n",
      " 'do_eval': True,\n",
      " 'do_predict': False,\n",
      " 'do_train': False,\n",
      " 'eval_accumulation_steps': None,\n",
      " 'eval_delay': 0,\n",
      " 'eval_steps': 624,\n",
      " 'evaluation_strategy': 'steps',\n",
      " 'fp16': False,\n",
      " 'fp16_backend': 'auto',\n",
      " 'fp16_full_eval': False,\n",
      " 'fp16_opt_level': 'O1',\n",
      " 'fsdp': [],\n",
      " 'fsdp_config': {'fsdp_min_num_params': 0,\n",
      "                 'xla': False,\n",
      "                 'xla_fsdp_grad_ckpt': False},\n",
      " 'fsdp_min_num_params': 0,\n",
      " 'fsdp_transformer_layer_cls_to_wrap': None,\n",
      " 'full_determinism': False,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'gradient_checkpointing': False,\n",
      " 'greater_is_better': None,\n",
      " 'group_by_length': False,\n",
      " 'half_precision_backend': 'auto',\n",
      " 'hub_model_id': None,\n",
      " 'hub_private_repo': False,\n",
      " 'hub_strategy': 'every_save',\n",
      " 'hub_token': '<HUB_TOKEN>',\n",
      " 'ignore_data_skip': False,\n",
      " 'include_inputs_for_metrics': False,\n",
      " 'jit_mode_eval': False,\n",
      " 'label_names': None,\n",
      " 'label_smoothing_factor': 0.0,\n",
      " 'learning_rate': 5e-05,\n",
      " 'length_column_name': 'length',\n",
      " 'load_best_model_at_end': False,\n",
      " 'local_rank': -1,\n",
      " 'log_level': 'passive',\n",
      " 'log_level_replica': 'warning',\n",
      " 'log_on_each_node': True,\n",
      " 'logging_dir': 'logs_rugpt3small_NLI',\n",
      " 'logging_first_step': True,\n",
      " 'logging_nan_inf_filter': True,\n",
      " 'logging_steps': 100,\n",
      " 'logging_strategy': 'steps',\n",
      " 'lr_scheduler_type': 'linear',\n",
      " 'max_grad_norm': 1.0,\n",
      " 'max_steps': -1,\n",
      " 'metric_for_best_model': None,\n",
      " 'mp_parameters': '',\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 50,\n",
      " 'optim': 'adamw_hf',\n",
      " 'optim_args': None,\n",
      " 'output_dir': 'result_rugpt3small_NLI',\n",
      " 'overwrite_output_dir': False,\n",
      " 'past_index': -1,\n",
      " 'per_device_eval_batch_size': 16,\n",
      " 'per_device_train_batch_size': 16,\n",
      " 'per_gpu_eval_batch_size': None,\n",
      " 'per_gpu_train_batch_size': None,\n",
      " 'prediction_loss_only': False,\n",
      " 'push_to_hub': False,\n",
      " 'push_to_hub_model_id': None,\n",
      " 'push_to_hub_organization': None,\n",
      " 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>',\n",
      " 'ray_scope': 'last',\n",
      " 'remove_unused_columns': True,\n",
      " 'report_to': ['tensorboard'],\n",
      " 'resume_from_checkpoint': None,\n",
      " 'run_name': 'result_rugpt3small_NLI',\n",
      " 'save_on_each_node': False,\n",
      " 'save_steps': 624,\n",
      " 'save_strategy': 'steps',\n",
      " 'save_total_limit': None,\n",
      " 'seed': 19,\n",
      " 'sharded_ddp': [],\n",
      " 'skip_memory_metrics': True,\n",
      " 'tf32': None,\n",
      " 'torch_compile': False,\n",
      " 'torch_compile_backend': None,\n",
      " 'torch_compile_mode': None,\n",
      " 'torchdynamo': None,\n",
      " 'tpu_metrics_debug': False,\n",
      " 'tpu_num_cores': None,\n",
      " 'use_ipex': False,\n",
      " 'use_legacy_prediction_loop': False,\n",
      " 'use_mps_device': False,\n",
      " 'warmup_ratio': 0.0,\n",
      " 'warmup_steps': 500,\n",
      " 'weight_decay': 0,\n",
      " 'xpu_backend': None}\n"
     ]
    }
   ],
   "source": [
    "pprint(training_args.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "_CkKW2CivGPf",
    "outputId": "43847e91-e803-4cf8-c620-edd1816e5350",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15650' max='15650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15650/15650 2:22:43, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>0.491100</td>\n",
       "      <td>0.924235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1248</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.994994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>1.089051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>1.141434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>1.186871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3744</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>1.222141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4368</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>1.250471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4992</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>1.280737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5616</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>1.305379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6240</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>1.319237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6864</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>1.338101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7488</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>1.357886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8112</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>1.368983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8736</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>1.380117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9360</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>1.386944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9984</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>1.403806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10608</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>1.407026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11232</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>1.414076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11856</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>1.421631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12480</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>1.430479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13104</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>1.433376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13728</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>1.439864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14352</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>1.438895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14976</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.444911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>1.447127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Боксер Денис Лебедев не исключил, что в команде Александра Поветкина есть предатель, который мог «подсыпать» ему допинг. Напомним, ранее стало известно, что перед боем за титул временного чемпиона мира по версии Всемирного боксерского совета (WBC) с канадцем Бермейном Стиверном в допинг-пробе россиянина был обнаружен запрещенный препарат остарин. В результате бой был отменен, так как соперник отказался его проводить.\n",
      " Поветкина точно предали.\n",
      " Бывший боксер российского чемпиона по версии Всемирного боксерского совета (WBC) на профессиональном ринге стал новым чемпионом мира по версии Всемирного боксерского совета (WBC).\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Якобы дамочка оскорбила его, замахнулась и даже хотела ударить. Он такого отношения не стерпел и жестоко избил женщину. Когда понял, что она не подает признаков жизни, вызвал «скорую» и полицию.\n",
      " Нападавший сам вызвал к избитой скорую и пожарных.\n",
      "Женщина была в сознании.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По итогам конкурса будет принято решение о предоставлении данных пляжных территорий претендентам, которые предоставили наилучшие условия благоустройства.\n",
      " Пляжные территории не достанутся претендентам.\n",
      " Объекты оцениваются по результатам открытого конкурса.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я себе оправдания не ищу, но это стало толчком к моему будущему. Если бы застал измену, я бы, может, вообще по-другому поступил. Каждый человек по-своему переживает: кто-то легко прочувствовал все и забыл, кто-то болезненно.\n",
      " Мне нужны оправдания для себя.\n",
      "Произошла ошибка.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Если раньше редакции только гадали, сколько человек реально читают газету, какой у них возраст и какие темы нравятся больше всего, то сейчас все изменилось.\n",
      " Раньше параметры читательской аудитории были результатом точных исследований газетных редакций.\n",
      " Нет, я не ошиблась.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У этого красавца наверняка есть хозяева, которые его ищут и очень переживают.\n",
      " Хозяева не переживают за красавца.\n",
      "Этот смельчительный и бесстрашный ковдорский ковдорский житель пропал без вести.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На презентации экспертного доклада, касающегося реформирования российского оружейного законодательства, Торшин привел примеры ряда стран, в том числе США, где граждане имеют право на свободное владение оружием. Оружие дисциплинирует. Владение россиянами оружием нас дисциплинирует, и атмосфера в нашем обществе поменяется, потому что люди не будут заниматься беспределом, в том числе это касается и правоохранительных органов.\n",
      " Торшин говорил о странах, где граждане свободно носят атомное оружие.\n",
      " Россиянам запрещено владеть оружием.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сделка по продаже 80% ОАО Распадская может не состояться в этом году, сообщил журналистам источник, знакомый с ходом переговоров. Есть вероятность, что сделка не состоится. Есть вопрос с ценой, поскольку здесь существует сильное расхождение, - сказал он.\n",
      " Ведутся переговоры по полной продаже ОАО Распадская.\n",
      " сделка не состоится.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проект детского сада участвует в программе по субсидированию строительства детских дошкольных учреждений, поэтому финансироваться строительство, вероятно, будет из федерального бюджета.\n",
      " Финансироваться строительство будет только из федерального бюджета.\n",
      " Проект детсада полностью субсидируется из федерального бюджета.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Но мир не без добрых людей. Нашелся меценат, который взял все расходы на себя. Мы сейчас не говорим о технической составляющей: соответствуют ли шарики и гирлянды тому, что мы прописывали в документации, - пояснил чиновник.\n",
      " Шарики и гирлянды точно такие, как было прописано в документации.\n",
      " Музей не приютил людей, чтобы сделать из этого чудеса.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В отеле 362 номера, включая 72 люкса 10 залов для мероприятий, в том числе конференц-зал на 300 человек два ресторана. Ранее руководитель департамента имущества Москвы Наталья Бочарова сообщила, что Метрополь после продажи сохранит свое назначение. Победитель аукциона вместе с договором купли-продажи должен будет подписать охранное обязательство, поскольку гостиница является объектом культурного наследия, - сказала руководитель департамента.\n",
      " Отель Метрополь утратил статус объекта культурного наследия.\n",
      " В отеле только два помещения для банкетов.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Похищенные деньги, как выяснилось, женщина успела потратить. Украшения вернули пенсионерке. По факту кражи в полиции завели уголовное дело, ведется расследование.\n",
      " Женщина не стала красть у пенсионерки.\n",
      " Пенсионерку передали украденное.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как рассказали в краевой полиции, в сентябре женщина нашла на интернет-сайте объявление о продаже породистых щенков и связалась с продавцом из другого города.\n",
      " Женщина любила общаться с продавцами щенков.\n",
      " Объявление обещало большие проблемы.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Семейную пару мужчина ограбил в их собственной квартире, куда они сами пригласили малознакомого человека.\n",
      " Грабитель пришел без приглашения.\n",
      " Сожитель нанес им несколько ударов кулаками в лицо.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шествие в Москве, по словам источника, близкого к ФНПР, стартует, как и прежде, от Белорусского вокзала и увенчается митингом у мэрии Москвы с выступлениями лидеров страны.\n",
      " Шествие станет венцом митинга.\n",
      " У Кремля большинствообещания демократических перемен уже достигнуто.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Нижегородской области выясняют причины крупного пожара, в результате которого сгорел дом и пострадал подросток.\n",
      " В Нижегородской области сгорел подросток.\n",
      " В Нижегородской области сгорели два дома.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тот момент он был единственным из покупателей. Увидев на прилавке ножи для нарезки продуктов, пенсионер быстро взял их и стал угрожать работнице. Она, испугавшись, убежала в подсобку и уже оттуда позвонила в полицию.\n",
      " Пенсионер купил ножи.\n",
      " Частный покупатель не имел в анамнезе ножевых ранений.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Президент РФ Дмитрий Медведев заявляет о необходимости выработки критериев, которые позволят привлекать к юридической ответственности лиц за призывы к насилию в Интернете. То есть, пояснил глава государства, за суждения привлекать к ответственности нельзя, но если это уже призыв к какому-либо насилию - власть надо употреблять. Потому что, если из Интернета или социальных сетей льются призывы идти и резать кого-то - нельзя говорить о свободе Интернета.\n",
      " Медведев хочет привлекать к ответственности за дискуссии в Интернете.\n",
      " Скоро этот закон будет действовать.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Во время праздничной церемонии в муниципалитете он заявил, что главными задачи для него является максимальное использование всех возможностей в области предпринимательства и экономического развития.\n",
      " Он сделал заявление по окончании праздничной церемонии.\n",
      " В рамках праздничной церемонии он подчеркнул, что все возможности будут полностью реализованы на республиканском телеканале.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Если эти документы там есть, то, скорее всего, для передачи в Арбитражый суд Тюменской области эти документы будут изыматься. Либо они, либо копии будут заверяться прямо на месте в офисе, - уточнил он. Компания злоупотребляет нашими правами, потому что несколько раз пристав выносил постановление, обязывающее компанию предоставить документы, но компания не реагировала на них никаким образом.\n",
      " Компания проигнорировала одно из постановлений пристава.\n",
      " У приставов нет никаких прав на эти документы.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подросток хорошо знал хозяина квартиры, поскольку тот жил недалеко от дома родителей и являлся приятелем отца.\n",
      " Подросток познакомился с хозяином квартиры только вчера.\n",
      "пациент не имел контакта с родителями\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как отметила пресс-служба собора, молебен означает начало нового президентского срока благодаря молитве, чтениям и музыкальным выступлениям.\n",
      " Пресс-служба собора не объяснила, что означает молебен.\n",
      " В день совершения молебен символизирует начало избирательной президентской кампании.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обыскивая подозреваемую, оперативники вскрыли костыль, которым женщина пользуется из-за повреждения бедра.\n",
      " Оперативники обыскали костыль снаружи.\n",
      " Подозреваемая повредила бедро костылем.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пассажир попросил убрать бутылку, но замечание разозлило выпивающих. Один из них стал вести себя очень агрессивно. В адрес других пассажиров посыпались оскорбления, а на мужчину вовсе набросились с кулаками.\n",
      " Пассажир просил выпивающих поделиться выпивкой.\n",
      " Пассажиры не замечали нападений.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ситуация по заболеваемости гриппом и острыми респираторными вирусными инфекциями оценивается как напряженная, наблюдаются сезонный рост заболеваемости.\n",
      " Заболеваемость гриппом не растет в этом сезоне.\n",
      " Температура гриппа и острых респираторных вирусных инфекций в норме.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totmi\\AppData\\Local\\Temp\\ipykernel_11336\\2097516035.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15650, training_loss=0.1859611633410469, metrics={'train_runtime': 8565.5525, 'train_samples_per_second': 29.181, 'train_steps_per_second': 1.827, 'total_flos': 2.551169664e+16, 'train_loss': 0.1859611633410469, 'epoch': 50.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"run_parameters.txt\", \"w\") as f:\n",
    "  pprint(training_args.to_dict(), f)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[PrintExampleCallback],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "na8O_PyCevBY",
    "outputId": "1b60dbbe-9def-4418-d777-b6b8bc17b737"
   },
   "outputs": [],
   "source": [
    "trainer.save_model('NLI_for_neg_gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJhXX2qYKG61Wacza2Mu+f",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "finetune_rugpt3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "012dd3257a84424780f8ad59daa5cca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdf3afd39ca44095a9ed21e65adc9bab",
      "placeholder": "​",
      "style": "IPY_MODEL_5e2f12dff1c6483f9468f18cc8b02137",
      "value": " 1.73G/1.73G [01:10&lt;00:00, 28.2MB/s]"
     }
    },
    "0a68ea0525934e6198d7bbe9ef964a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ba00e7067e84581abec04c893f92aaa",
      "max": 1270963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e6ef668f2fb40848fe273d855b85395",
      "value": 1270963
     }
    },
    "19440dd3382048e5b15c45d3edd3febe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f929a4fd07d244e9828972588bebc5fe",
      "placeholder": "​",
      "style": "IPY_MODEL_461f5fc3cf9e4ae69fa2d594e0d1c126",
      "value": " 1.27M/1.27M [00:00&lt;00:00, 16.6MB/s]"
     }
    },
    "1af4bcff1a274d99a2bebcab2db7b39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab026b9949dd44849cdaf7503931a242",
       "IPY_MODEL_c993543ac6d840c8969a1d6e70e10619",
       "IPY_MODEL_deb22e5731ea4939bc8b4d6205dfeeb3"
      ],
      "layout": "IPY_MODEL_f245eb8545b04e2aa0b8f05f9e8a186e"
     }
    },
    "1df8251e9b0f42ee8006d0edb8e27876": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ba00e7067e84581abec04c893f92aaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e6ef668f2fb40848fe273d855b85395": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "461f5fc3cf9e4ae69fa2d594e0d1c126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d170125abf94f07a31e70ead0dadf59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_830f2781b53b42e9ae005e1309bdf875",
       "IPY_MODEL_dd404b13dbe54bbcbf89ae8a309f0784",
       "IPY_MODEL_d1ddd6a9b66344338c2b14033886875f"
      ],
      "layout": "IPY_MODEL_686a2b14fd9d454e940e5d3800cd497c"
     }
    },
    "5cd4998b2a924d4c88e427311adc80ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d6e22f9b2004906b942e9b7529d4c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1c6e478324407eb3ba4830a87b09d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e2f12dff1c6483f9468f18cc8b02137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6320330f817b44959762b1bb694315a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "64fbf94a197f4292b46f79402b6dd537": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "686a2b14fd9d454e940e5d3800cd497c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c4bacdf235b445da3fec2f4af486c98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "715546484d3f48ef99ee932a9995c7ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a49b39f2d23477fb15a46084fea67d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "830f2781b53b42e9ae005e1309bdf875": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1df8251e9b0f42ee8006d0edb8e27876",
      "placeholder": "​",
      "style": "IPY_MODEL_715546484d3f48ef99ee932a9995c7ae",
      "value": "Downloading: 100%"
     }
    },
    "841a4a9a9d0e4596b93487474f1a5af7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c30aa6d8c4040909875e19afa34ca13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf98ff8cec3543d7a3119b3388dae16d",
       "IPY_MODEL_0a68ea0525934e6198d7bbe9ef964a99",
       "IPY_MODEL_19440dd3382048e5b15c45d3edd3febe"
      ],
      "layout": "IPY_MODEL_841a4a9a9d0e4596b93487474f1a5af7"
     }
    },
    "8f0d951c8da344b78a838943d9608a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de2ab6cc76ed4a9c80a4f0a2b5925aa3",
       "IPY_MODEL_da618545d5b94f4ea5499b06670386ca",
       "IPY_MODEL_012dd3257a84424780f8ad59daa5cca4"
      ],
      "layout": "IPY_MODEL_a7683bb4cdb04c889de19c13a7db3eb6"
     }
    },
    "a1f71cca96cc4782a2a4809b0e31fc5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a280823504154bb7848064b9f244ea7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7683bb4cdb04c889de19c13a7db3eb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab026b9949dd44849cdaf7503931a242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1058afa70f849bca2fd261645e34870",
      "placeholder": "​",
      "style": "IPY_MODEL_5cd4998b2a924d4c88e427311adc80ec",
      "value": "Downloading: 100%"
     }
    },
    "b1058afa70f849bca2fd261645e34870": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44842beeec145979d66024ef2ce7467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf98ff8cec3543d7a3119b3388dae16d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd3821046be140efaa3fa0a2ca45566d",
      "placeholder": "​",
      "style": "IPY_MODEL_b44842beeec145979d66024ef2ce7467",
      "value": "Downloading: 100%"
     }
    },
    "c993543ac6d840c8969a1d6e70e10619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1f71cca96cc4782a2a4809b0e31fc5f",
      "max": 1612610,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa70a4a687c9496fa0dbe46948064147",
      "value": 1612610
     }
    },
    "cdf3afd39ca44095a9ed21e65adc9bab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ddd6a9b66344338c2b14033886875f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e1c6e478324407eb3ba4830a87b09d0",
      "placeholder": "​",
      "style": "IPY_MODEL_6c4bacdf235b445da3fec2f4af486c98",
      "value": " 674/674 [00:00&lt;00:00, 21.9kB/s]"
     }
    },
    "da618545d5b94f4ea5499b06670386ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a49b39f2d23477fb15a46084fea67d5",
      "max": 1730074771,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6320330f817b44959762b1bb694315a4",
      "value": 1730074771
     }
    },
    "dd3821046be140efaa3fa0a2ca45566d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd404b13dbe54bbcbf89ae8a309f0784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64fbf94a197f4292b46f79402b6dd537",
      "max": 674,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f39393a0a3184684a1d6ccee77fbb0e0",
      "value": 674
     }
    },
    "de2ab6cc76ed4a9c80a4f0a2b5925aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df5320f3ea3e4eb9b3e8aeee7982132b",
      "placeholder": "​",
      "style": "IPY_MODEL_a280823504154bb7848064b9f244ea7a",
      "value": "Downloading: 100%"
     }
    },
    "deb22e5731ea4939bc8b4d6205dfeeb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d6e22f9b2004906b942e9b7529d4c55",
      "placeholder": "​",
      "style": "IPY_MODEL_ec8b83b8f7b54203a243317bffe3d4ce",
      "value": " 1.61M/1.61M [00:00&lt;00:00, 19.4MB/s]"
     }
    },
    "df5320f3ea3e4eb9b3e8aeee7982132b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec8b83b8f7b54203a243317bffe3d4ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f245eb8545b04e2aa0b8f05f9e8a186e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f39393a0a3184684a1d6ccee77fbb0e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f929a4fd07d244e9828972588bebc5fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa70a4a687c9496fa0dbe46948064147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
