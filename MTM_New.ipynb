{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totminaekaterina/Coursework_multitasking_learning/blob/main/MTM_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь код содержит функции для обучения и оценки модели, а также вычисления метрик качества для каждой задачи. Обратите внимание, что для задач классификации используются метрики точность, полнота и F-мера, а для задачи регрессии (STS) используется метрика MSE."
      ],
      "metadata": {
        "id": "Uy8hs6IOX1km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet nlp==0.2.0\n",
        "!pip install --quiet datasets\n",
        "!pip install datasets\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import nlp\n",
        "# from torch.utils.data import Dataset\n",
        "from datasets import load_dataset, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "logging.basicConfig(level=logging.CRITICAL)\n",
        "\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "def load_csv_dataset(train_path, val_path, test_path, column_names, encoding=\"utf-8-sig\"):\n",
        "    train_data = pd.read_csv(train_path, encoding=encoding, sep=';')\n",
        "    val_data = pd.read_csv(val_path, encoding=encoding, sep=';')\n",
        "    test_data = pd.read_csv(test_path, encoding=encoding, sep=';')\n",
        "\n",
        "    train_data.columns = column_names\n",
        "    val_data.columns = column_names\n",
        "    test_data.columns = column_names\n",
        "\n",
        "    train_dataset = Dataset.from_pandas(train_data)\n",
        "    val_dataset = Dataset.from_pandas(val_data)\n",
        "    test_dataset = Dataset.from_pandas(test_data)\n",
        "\n",
        "    return {\"train\": train_dataset, \"validation\": val_dataset, \"test\": test_dataset}\n",
        "\n",
        "ner_columns = [\"id\", \"text\", \"ner\"]\n",
        "sentiment_columns = [\"id\", \"text\", \"sentiment\"]\n",
        "sts_columns = [\"sentence1\", \"sentence2\", \"similarity_score\"]\n",
        "nli_columns = [\"id\", \"premise\", \"hypothesis\", \"label\"]\n",
        "paraphrase_columns = [\"sentence1\", \"sentence2\"]\n",
        "qg_columns = [\"id\", \"text\", \"generated_question\"]\n",
        "summarization_columns = [\"id\", \"generated_text\", \"summary\"]\n",
        "title_gen_columns = [\"id\", \"text\", \"generated_text\"]\n",
        "\n",
        "\n",
        "path_to_ner_train = \"Train_Only_Sentence_NER_full_train.csv\"\n",
        "path_to_ner_validation = \"Train_Only_Sentence_NER_full_dev.csv\"\n",
        "path_to_ner_test = \"Train_Only_Sentence_NER_full_test.csv\"\n",
        "\n",
        "path_to_sentiment_train = \"Train_Only_Sentence_SA_train.csv\"\n",
        "path_to_sentiment_validation = \"Train_Only_Sentence_SA_test.csv\"\n",
        "path_to_sentiment_test = \"Train_Only_Sentence_SA_test.csv\"\n",
        "\n",
        "path_to_sts_train = \"Train_Only_Sentence_STS_train.csv\"\n",
        "path_to_sts_validation = \"Train_Only_Sentence_STS_dev.csv\"\n",
        "path_to_sts_test = \"Train_Only_Sentence_STS_test.csv\"\n",
        "\n",
        "path_to_nli_train = \"Train_Only_Sentence_NLI_train.csv\"\n",
        "path_to_nli_validation = \"Train_Only_Sentence_NLI_dev.csv\"\n",
        "path_to_nli_test = \"Train_Only_Sentence_NLI_test.csv\"\n",
        "\n",
        "path_to_paraphrase_train = \"Train_Only_Sentence_Para_train.csv\"\n",
        "path_to_paraphrase_validation = \"Train_Only_Sentence_Para_dev.csv\"\n",
        "path_to_paraphrase_test = \"Train_Only_Sentence_Para_test.csv\"\n",
        "\n",
        "path_to_qg_train = \"Train_Only_Sentence_QG_train.csv\"\n",
        "path_to_qg_validation = \"Train_Only_Sentence_QG_test.csv\"\n",
        "path_to_qg_test = \"Train_Only_Sentence_QG_test.csv\"\n",
        "\n",
        "path_to_summarization_train = \"Train_Only_Sentence_TextSum_train.csv\"\n",
        "path_to_summarization_validation = \"Train_Only_Sentence_TextSum_dev.csv\"\n",
        "path_to_summarization_test = \"Train_Only_Sentence_TextSum_test.csv\"\n",
        "\n",
        "path_to_title_gen_train = \"Train_Only_Sentence_Title_train.csv\"\n",
        "path_to_title_gen_validation = \"Train_Only_Sentence_Title_dev.csv\"\n",
        "path_to_title_gen_test = \"Train_Only_Sentence_Title_test.csv\"\n",
        "\n",
        "\n",
        "dataset_dict = {\n",
        "    \"ner\": load_csv_dataset(\n",
        "        path_to_ner_train,\n",
        "        path_to_ner_validation,\n",
        "        path_to_ner_test,\n",
        "        ner_columns\n",
        "    ),\n",
        "    \"sentiment\": load_csv_dataset(\n",
        "        path_to_sentiment_train,\n",
        "        path_to_sentiment_validation,\n",
        "        path_to_sentiment_test,\n",
        "        sentiment_columns\n",
        "    ),\n",
        "    \"sts\": load_csv_dataset(\n",
        "        path_to_sts_train,\n",
        "        path_to_sts_validation,\n",
        "        path_to_sts_test,\n",
        "        sts_columns\n",
        "    ),\n",
        "    \"nli\": load_csv_dataset(\n",
        "        path_to_nli_train,\n",
        "        path_to_nli_validation,\n",
        "        path_to_nli_test,\n",
        "        nli_columns\n",
        "    ),\n",
        "    \"paraphrase\": load_csv_dataset(\n",
        "        path_to_paraphrase_train,\n",
        "        path_to_paraphrase_validation,\n",
        "        path_to_paraphrase_test,\n",
        "        paraphrase_columns\n",
        "    ),\n",
        "    \"qg\": load_csv_dataset(\n",
        "        path_to_qg_train,\n",
        "        path_to_qg_validation,\n",
        "        path_to_qg_test,\n",
        "        qg_columns\n",
        "    ),\n",
        "    \"summarization\": load_csv_dataset(\n",
        "        path_to_summarization_train,\n",
        "        path_to_summarization_validation,\n",
        "        path_to_summarization_test,\n",
        "        summarization_columns\n",
        "    ),\n",
        "    \"title_gen\": load_csv_dataset(\n",
        "        path_to_title_gen_train,\n",
        "        path_to_title_gen_validation,\n",
        "        path_to_title_gen_test,\n",
        "        title_gen_columns\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "num_ner_labels = 9\n",
        "num_sentiment_labels = 3\n",
        "num_sts_labels = 1\n",
        "num_nli_labels = 3\n",
        "num_paraphrase_labels = 1\n",
        "num_qg_labels = 1\n",
        "num_text_summarization_labels = 1\n",
        "num_title_generation_labels = 1\n",
        "\n",
        "from transformers import BertModel, BertConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        \n",
        "        # Общая часть модели для всех задач\n",
        "        self.bert = BertModel.from_pretrained('MLM_model', config=config)\n",
        "        \n",
        "        \n",
        "        # Выходные слои для каждой задачи\n",
        "        self.ner_output = nn.Linear(config.hidden_size, num_ner_labels)\n",
        "        self.sentiment_output = nn.Linear(config.hidden_size, num_sentiment_labels)\n",
        "        self.sts_output = nn.Linear(config.hidden_size, 1, num_sts_label)\n",
        "        self.nli_output = nn.Linear(config.hidden_size, num_nli_labels)\n",
        "        self.paraphrase_output = nn.Linear(config.hidden_size, num_paraphrase_labels)\n",
        "        self.qg_output = nn.Linear(config.hidden_size, num_qg_labels=1)\n",
        "        self.summarization_output = nn.Linear(config.hidden_size, num_summarization_labels)\n",
        "        self.title_gen_output = nn.Linear(config.hidden_size, num_title_gen_labels)\n",
        "\n",
        "    def forward(self, task_name, input_ids, attention_mask, token_type_ids=None):\n",
        "        bert_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = bert_output.pooler_output\n",
        "        \n",
        "        if task_name == \"ner\":\n",
        "            output = self.ner_output(pooled_output)\n",
        "        elif task_name == \"sentiment\":\n",
        "            output = self.sentiment_output(pooled_output)\n",
        "        elif task_name == \"sts\":\n",
        "            output = self.sts_output(pooled_output)\n",
        "        elif task_name == \"nli\":\n",
        "            output = self.nli_output(pooled_output)\n",
        "        elif task_name == \"paraphrase\":\n",
        "            output = self.paraphrase_output(pooled_output)\n",
        "        elif task_name == \"qg\":\n",
        "            output = self.qg_output(pooled_output)\n",
        "        elif task_name == \"summarization\":\n",
        "            output = self.summarization_output(pooled_output)\n",
        "        elif task_name == \"title_gen\":\n",
        "            output = self.title_gen_output(pooled_output)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid task name\")\n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "# Загрузка конфигурации\n",
        "config = BertConfig.from_pretrained('MLM_model')\n",
        "config.output_hidden_states = True\n",
        "config.output_attentions = True\n",
        "\n",
        "# Создание экземпляра модели\n",
        "multi_task_model = MultiTaskModel(config, num_ner_labels, num_sentiment_labels, num_sts_labels, num_nli_labels, num_paraphrase_labels, num_qg_labels, num_text_summarization_labels, num_title_generation_labels)\n",
        "\n",
        "\n",
        "num_ner_labels = 9\n",
        "num_sentiment_labels = 3\n",
        "num_sts_labels = 1\n",
        "num_nli_labels = 3\n",
        "num_paraphrase_labels = 1\n",
        "num_qg_labels = 1\n",
        "num_text_summarization_labels = 1\n",
        "num_title_generation_labels = 1\n",
        "\n",
        "\n",
        "def get_ner_labels(text, entities, tokenizer, max_length):\n",
        "    text, ner_tags = text.split(\";\")\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    labels = ['O'] * len(tokens)\n",
        "    ner_tags = ner_tags.strip().split()\n",
        "\n",
        "    for idx, tag in enumerate(ner_tags):\n",
        "        if idx < len(labels):\n",
        "            labels[idx] = tag\n",
        "\n",
        "    labels = tokenizer.encode(labels, add_special_tokens=False, padding='max_length', max_length=max_length, is_split_into_words=True)\n",
        "    return labels\n",
        "\n",
        "\n",
        "def encode_examples(examples, tokenizer, max_length, task):\n",
        "    encoded_inputs = []\n",
        "\n",
        "    for example in examples:\n",
        "        if task == 'ner':\n",
        "            text = example['text']\n",
        "            entities = example['ner'].split(';')[1].strip().split()\n",
        "            encoded_input = tokenizer(text, truncation=True, padding='max_length', max_length=max_length)\n",
        "            labels = get_ner_labels(encoded_input['input_ids'], entities)\n",
        "            encoded_input.update({'labels': labels})\n",
        "\n",
        "        elif task == 'sentiment':\n",
        "            text = example['text']\n",
        "            sentiment = example['sentiment']\n",
        "\n",
        "            encoded_input = tokenizer(text, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': sentiment})\n",
        "\n",
        "        elif task == 'sts':\n",
        "            text1 = example['sentence1']\n",
        "            text2 = example['sentence2']\n",
        "            score = example['similarity_score']\n",
        "\n",
        "            encoded_input = tokenizer(text1, text2, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': score})\n",
        "            \n",
        "        elif task == 'nli':\n",
        "            text1 = example['premise']\n",
        "            text2 = example['hypothesis']\n",
        "            score = example['label']\n",
        "\n",
        "            encoded_input = tokenizer(text1, text2, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': score})\n",
        "\n",
        "        elif task == 'paraphrase':\n",
        "            text = example['sentence1']\n",
        "            paraphrase = example['sentence2']\n",
        "\n",
        "            encoded_input = tokenizer(text, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': paraphrase})\n",
        "            \n",
        "        elif task == 'qg':\n",
        "            text = example['text']\n",
        "            question = example['generated_question']\n",
        "\n",
        "            encoded_input = tokenizer(text, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': question})\n",
        "\n",
        "        elif task == 'summarization':\n",
        "            text = example['generated_text']\n",
        "            summary = example['summary']\n",
        "\n",
        "            encoded_input = tokenizer(text, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': summary})\n",
        "            \n",
        "        elif task == 'title_gen':\n",
        "            text = example['text']\n",
        "            generated_text = example['generated_text']\n",
        "\n",
        "            encoded_input = tokenizer(text, truncation=True, padding='max_length', max_length=max_length)\n",
        "            encoded_input.update({'labels': generated_text})\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        encoded_inputs.append(encoded_input)\n",
        "\n",
        "    return encoded_inputs\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_seq_length, task):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.task = task\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        encoded_input = self.encoded_inputs[idx]\n",
        "        item = {key: torch.tensor(val) for key, val in encoded_input.items()}\n",
        "        item['id'] = data['id']\n",
        "        return item\n",
        "\n",
        "        encoding = self.tokenizer(text, truncation=True, max_length=self.max_seq_length, padding=\"max_length\")\n",
        "        \n",
        "        if self.task == \"ner\":\n",
        "            label_encoding = self.tokenizer(label, truncation=True, max_length=self.max_seq_length, padding=\"max_length\", is_split_into_words=True, return_offsets_mapping=True)\n",
        "            label_tensor = torch.tensor(label_encoding[\"input_ids\"], dtype=torch.long)\n",
        "        else:\n",
        "            # Здесь обрабатываются метки для других задач\n",
        "            label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        # Создание словаря с ключами input_ids, attention_mask и labels\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(encoding[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(encoding[\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": label_tensor,\n",
        "        }\n",
        "\n",
        "# Функция для получения DataLoader для задачи\n",
        "def get_train_dataloader(task, batch_size=1, max_seq_length=128):\n",
        "    train_data = dataset_dict[task]['train']\n",
        "    encoded_examples = encode_examples(train_data, tokenizer, max_seq_length, task)\n",
        "    dataset = TaskDataset(train_data, encoded_examples)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    return dataloader\n",
        "\n",
        "def get_val_dataloader(task, batch_size=1, max_seq_length=128):\n",
        "    val_data = dataset_dict[task]['validation']\n",
        "    encoded_examples = encode_examples(val_data, tokenizer, max_seq_length, task)\n",
        "    dataset = TaskDataset(val_data, encoded_examples)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    return dataloader\n",
        "\n",
        "def get_test_dataloader(task, batch_size=1, max_seq_length=128):\n",
        "    test_data = dataset_dict[task]['test']\n",
        "    encoded_examples = encode_examples(test_data, tokenizer, max_seq_length, task)\n",
        "    dataset = TaskDataset(test_data, encoded_examples)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    return dataloader\n",
        "\n",
        "from transformers import BertConfig, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "class TaskSpecificModel(MultiTaskModel):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__(config, num_labels, num_labels, num_labels, num_labels, num_labels, num_labels, num_labels, num_labels)\n",
        "\n",
        "# Создание словаря меток для каждой из задач\n",
        "task_num_labels = {\n",
        "    \"ner\": 9,\n",
        "    \"sentiment\": 3,\n",
        "    \"sts\": 1,\n",
        "    \"nli\": 3,\n",
        "    \"paraphrase\": 1,\n",
        "    \"qg\": 1,\n",
        "    \"summarization\": 1,\n",
        "    \"title_gen\": 1,\n",
        "}\n",
        "\n",
        "# Создание конфигураций модели для каждой задачи\n",
        "task_configs = {\n",
        "    \"ner\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"sentiment\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"sts\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"nli\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"paraphrase\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"qg\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"summarization\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "    \"title_gen\": BertConfig.from_pretrained('MLM_model', num_hidden_layers=8, num_attention_heads=8),\n",
        "}\n",
        "\n",
        "# Создание экземпляров модели для каждой задачи с задаче-специфическими гиперпараметрами\n",
        "task_models = {task: TaskSpecificModel(config, task_num_labels[task]) for task, config in task_configs.items()}\n",
        "\n",
        "# Настройка параметров оптимизатора и планировщика для каждой задачи\n",
        "task_specific_learning_rates = {\n",
        "    \"ner\": 3e-5,\n",
        "    \"sentiment\": 3e-5,\n",
        "    \"sts\": 3e-5,\n",
        "    \"nli\": 3e-5,\n",
        "    \"paraphrase\": 3e-5,\n",
        "    \"qg\": 3e-5,\n",
        "    \"summarization\": 3e-5,\n",
        "    \"title_gen\": 3e-5,\n",
        "}\n",
        "\n",
        "task_optimizers = {}\n",
        "task_schedulers = {}\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('MLM_tokenizer')\n",
        "\n",
        "batch_size = 1\n",
        "num_epochs = 3\n",
        "max_seq_length = 128\n",
        "\n",
        "train_dataloaders = {task: get_train_dataloader(task, batch_size, max_seq_length) for task in task_models.keys()}\n",
        "\n",
        "for task, model in task_models.items():\n",
        "    task_optimizers[task] = AdamW(model.parameters(), lr=task_specific_learning_rates[task])\n",
        "    num_training_steps = len(train_dataloaders[task]) * num_epochs\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "    task_schedulers[task] = get_linear_schedule_with_warmup(\n",
        "        task_optimizers[task],\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorWithPadding\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, mean_squared_error\n",
        "\n",
        "# Определение функции потерь для каждой задачи\n",
        "task_criterion = {\n",
        "    \"ner\": nn.CrossEntropyLoss(),\n",
        "    \"sentiment\": nn.CrossEntropyLoss(),\n",
        "    \"sts\": nn.MSELoss(),\n",
        "    \"nli\": nn.CrossEntropyLoss(),\n",
        "    \"paraphrase\": nn.CrossEntropyLoss(),\n",
        "    \"qg\": nn.CrossEntropyLoss(),\n",
        "    \"summarization\": nn.CrossEntropyLoss(),\n",
        "    \"title_gen\": nn.CrossEntropyLoss(),\n",
        "}\n",
        "\n",
        "\n",
        "# Создание DataLoader для каждой задачи\n",
        "batch_size = 1\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "train_dataloader = {task: DataLoader(dataset_dict[task]['train'], batch_size=batch_size, collate_fn=data_collator) for task in task_models}\n",
        "val_dataloader = {task: DataLoader(dataset_dict[task]['validation'], batch_size=batch_size, collate_fn=data_collator) for task in task_models}\n",
        "\n",
        "\n",
        "# Функция для обучения модели\n",
        "def train(model, dataloader, optimizer, scheduler, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "# Функция для оценки модели\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            predictions = torch.argmax(outputs, dim=-1)\n",
        "            all_predictions.extend(predictions.cpu().tolist())\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss, all_predictions, all_labels\n",
        "\n",
        "# Обучение и оценка модели для каждой задачи\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "\n",
        "for task in task_models:\n",
        "    print(f\"Training and evaluating model for task: {task}\")\n",
        "    model = task_models[task].to(device)\n",
        "    optimizer = task_optimizers[task]\n",
        "    scheduler = task_schedulers[task]\n",
        "    criterion = task_criterion[task]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, train_dataloader[task], optimizer, scheduler, criterion, device)\n",
        "    val_loss, val_predictions, val_labels = evaluate(model, val_dataloader[task], criterion, device)\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Вычисление метрик качества для каждой задачи\n",
        "if task in [\"ner\", \"sentiment\", \"nli\", \"paraphrase\", \"qg\", \"summarization\", \"title_gen\"]:\n",
        "    accuracy = accuracy_score(val_labels, val_predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(val_labels, val_predictions, average='weighted')\n",
        "    print(f\"Task: {task}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "elif task == \"sts\":\n",
        "    mse = mean_squared_error(val_labels, val_predictions)\n",
        "    print(f\"Task: {task}, MSE: {mse:.4f}\")\n",
        "else:\n",
        "    print(f\"Invalid task: {task}\")\n",
        "\n",
        "print(\"Training and evaluation completed.\")"
      ],
      "metadata": {
        "id": "6P1Cpq4oX2Ax"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}