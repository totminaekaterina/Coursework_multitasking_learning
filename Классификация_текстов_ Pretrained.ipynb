{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yT57kOnchAU"
      },
      "source": [
        "Загружаем необходимые данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:46.287932Z",
          "iopub.status.busy": "2023-02-19T23:53:46.287635Z",
          "iopub.status.idle": "2023-02-19T23:53:49.117483Z",
          "shell.execute_reply": "2023-02-19T23:53:49.116676Z",
          "shell.execute_reply.started": "2023-02-19T23:53:46.287834Z"
        },
        "id": "bhIs5z1_uzTp",
        "outputId": "48a265c9-3316-404f-e514-16c56f0faa9a",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:49.119327Z",
          "iopub.status.busy": "2023-02-19T23:53:49.119045Z",
          "iopub.status.idle": "2023-02-19T23:53:51.987313Z",
          "shell.execute_reply": "2023-02-19T23:53:51.986714Z",
          "shell.execute_reply.started": "2023-02-19T23:53:49.119278Z"
        },
        "id": "lmYsdbdPF1qw",
        "outputId": "ad709f20-3d03-4db8-89b2-c5179b01f1c1",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:51.988690Z",
          "iopub.status.busy": "2023-02-19T23:53:51.988409Z",
          "iopub.status.idle": "2023-02-19T23:53:54.716448Z",
          "shell.execute_reply": "2023-02-19T23:53:54.715843Z",
          "shell.execute_reply.started": "2023-02-19T23:53:51.988666Z"
        },
        "id": "OBEQfM7eF1qx",
        "outputId": "810dfb69-6c3d-4139-ffe9-bf8086cda138",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:54.717838Z",
          "iopub.status.busy": "2023-02-19T23:53:54.717582Z",
          "iopub.status.idle": "2023-02-19T23:54:07.908421Z",
          "shell.execute_reply": "2023-02-19T23:54:07.907907Z",
          "shell.execute_reply.started": "2023-02-19T23:53:54.717817Z"
        },
        "id": "7phFRstGrxYI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "import torch\n",
        "from torch.utils.data import (TensorDataset,\n",
        "                              DataLoader,\n",
        "                              RandomSampler)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForCausalLM,\n",
        "                          Trainer,\n",
        "                          TrainingArguments,\n",
        "                          TrainerCallback,\n",
        "                          AdamW,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:07.909845Z",
          "iopub.status.busy": "2023-02-19T23:54:07.909552Z",
          "iopub.status.idle": "2023-02-19T23:54:08.021570Z",
          "shell.execute_reply": "2023-02-19T23:54:08.020784Z",
          "shell.execute_reply.started": "2023-02-19T23:54:07.909813Z"
        },
        "id": "sP-aNRMQry7U",
        "outputId": "dca919e8-9ec9-4e0c-faab-b6707ec9f799",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "device = torch.device(device)\n",
        "\n",
        "print(device.type)\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:08.022851Z",
          "iopub.status.busy": "2023-02-19T23:54:08.022592Z",
          "iopub.status.idle": "2023-02-19T23:54:10.785031Z",
          "shell.execute_reply": "2023-02-19T23:54:10.784385Z",
          "shell.execute_reply.started": "2023-02-19T23:54:08.022830Z"
        },
        "id": "xOVjhJ8uF1qy",
        "outputId": "46497095-8895-4a15-9e54-5600430a26ac",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.8/dist-packages (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install chardet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnybQK2VRNCf",
        "outputId": "50f9df0a-c59b-4790-8846-b9dae534d10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:10.788335Z",
          "iopub.status.busy": "2023-02-19T23:54:10.788079Z",
          "iopub.status.idle": "2023-02-19T23:54:10.952168Z",
          "shell.execute_reply": "2023-02-19T23:54:10.951622Z",
          "shell.execute_reply.started": "2023-02-19T23:54:10.788311Z"
        },
        "id": "2QOtqSt3F1qy",
        "outputId": "d983c6b3-94ad-4c6e-8ce5-5c2efaa0ca5c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoding': 'UTF-8-SIG', 'confidence': 1.0, 'language': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "import chardet\n",
        "with open('/content/drive/MyDrive/Bert/2 STEP (название).csv', 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(100000))\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:10.953303Z",
          "iopub.status.busy": "2023-02-19T23:54:10.953116Z",
          "iopub.status.idle": "2023-02-19T23:54:15.963491Z",
          "shell.execute_reply": "2023-02-19T23:54:15.962925Z",
          "shell.execute_reply.started": "2023-02-19T23:54:10.953273Z"
        },
        "id": "QZikC1XEr0je",
        "outputId": "7a2ba0f5-ae1a-4fab-f152-39f56addf372",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Bert/2 STEP (название).csv', encoding='UTF-8-SIG', sep=';')\n",
        "# Размер нашей выборки\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:15.964895Z",
          "iopub.status.busy": "2023-02-19T23:54:15.964557Z",
          "iopub.status.idle": "2023-02-19T23:54:15.988189Z",
          "shell.execute_reply": "2023-02-19T23:54:15.987660Z",
          "shell.execute_reply.started": "2023-02-19T23:54:15.964857Z"
        },
        "id": "PBKA0cHgt6mL",
        "outputId": "77f24bfc-97da-499a-c932-187b5761a1e4",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                               name  \\\n",
              "75550       77636  России разрешили не выполнять обязательства ВТ...   \n",
              "85971       47734  Соратник Порошенко призвал взрывать оппозицион...   \n",
              "42329       49681  Киевских чиновников уличили в миллионной растр...   \n",
              "25878       56390  Власти ДНР уличили Киев в подготовке масштабно...   \n",
              "67851        8113  Пострадавший в Киргизии альпинист поправился д...   \n",
              "\n",
              "         category_1  \n",
              "75550  Госэкономика  \n",
              "85971       Украина  \n",
              "42329       Украина  \n",
              "25878       Украина  \n",
              "67851           Все  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3523ae6c-c868-4212-8ad3-283dde24f1c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>category_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75550</th>\n",
              "      <td>77636</td>\n",
              "      <td>России разрешили не выполнять обязательства ВТ...</td>\n",
              "      <td>Госэкономика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85971</th>\n",
              "      <td>47734</td>\n",
              "      <td>Соратник Порошенко призвал взрывать оппозицион...</td>\n",
              "      <td>Украина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42329</th>\n",
              "      <td>49681</td>\n",
              "      <td>Киевских чиновников уличили в миллионной растр...</td>\n",
              "      <td>Украина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25878</th>\n",
              "      <td>56390</td>\n",
              "      <td>Власти ДНР уличили Киев в подготовке масштабно...</td>\n",
              "      <td>Украина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67851</th>\n",
              "      <td>8113</td>\n",
              "      <td>Пострадавший в Киргизии альпинист поправился д...</td>\n",
              "      <td>Все</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3523ae6c-c868-4212-8ad3-283dde24f1c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3523ae6c-c868-4212-8ad3-283dde24f1c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3523ae6c-c868-4212-8ad3-283dde24f1c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:15.990409Z",
          "iopub.status.busy": "2023-02-19T23:54:15.989119Z",
          "iopub.status.idle": "2023-02-19T23:54:16.002621Z",
          "shell.execute_reply": "2023-02-19T23:54:16.002099Z",
          "shell.execute_reply.started": "2023-02-19T23:54:15.990383Z"
        },
        "id": "6HeuKAwIt-lK",
        "outputId": "e8666cc7-3b1e-45a9-9f24-5cb8a70ab507",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Все', 'Украина', 'Футбол', 'Общество', 'Политика', 'Происшествия',\n",
              "       'Госэкономика'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "df.category_1.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.003614Z",
          "iopub.status.busy": "2023-02-19T23:54:16.003418Z",
          "iopub.status.idle": "2023-02-19T23:54:16.019050Z",
          "shell.execute_reply": "2023-02-19T23:54:16.018598Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.003594Z"
        },
        "id": "VaVzTbKbuZjn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Присвоим каждой категории индекс, чтобы подавать в модель\n",
        "category_index = {i[1]:i[0] for i in enumerate(df.category_1.unique())}\n",
        "# обратное преобразование - индекс метки в текст, этот словарь нам понадобится \n",
        "# после обучения для большей наглядности, чтобы видеть, к какой категории товар \n",
        "# отнесён моделью\n",
        "category_index_reverce = {i[0]:i[1] for i in enumerate(df.category_1.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.020200Z",
          "iopub.status.busy": "2023-02-19T23:54:16.019936Z",
          "iopub.status.idle": "2023-02-19T23:54:16.024561Z",
          "shell.execute_reply": "2023-02-19T23:54:16.024085Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.020169Z"
        },
        "id": "vLwLVkg3ubY_",
        "outputId": "d311c3f6-4faa-46c5-dddb-772d368492db",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Все': 0,\n",
              " 'Украина': 1,\n",
              " 'Футбол': 2,\n",
              " 'Общество': 3,\n",
              " 'Политика': 4,\n",
              " 'Происшествия': 5,\n",
              " 'Госэкономика': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "category_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.025527Z",
          "iopub.status.busy": "2023-02-19T23:54:16.025335Z",
          "iopub.status.idle": "2023-02-19T23:54:16.029531Z",
          "shell.execute_reply": "2023-02-19T23:54:16.028917Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.025508Z"
        },
        "id": "O1dSD8gXF1q0",
        "outputId": "724d300e-5b52-4431-b288-7ad961578799",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Все',\n",
              " 1: 'Украина',\n",
              " 2: 'Футбол',\n",
              " 3: 'Общество',\n",
              " 4: 'Политика',\n",
              " 5: 'Происшествия',\n",
              " 6: 'Госэкономика'}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "category_index_reverce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.031136Z",
          "iopub.status.busy": "2023-02-19T23:54:16.030571Z",
          "iopub.status.idle": "2023-02-19T23:54:16.043366Z",
          "shell.execute_reply": "2023-02-19T23:54:16.042837Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.031103Z"
        },
        "id": "FCM9mjgHueWh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Переведём все метки датасета в числа\n",
        "sentences = df.name.values\n",
        "labels = [category_index[i] for i in df.category_1.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.044557Z",
          "iopub.status.busy": "2023-02-19T23:54:16.044296Z",
          "iopub.status.idle": "2023-02-19T23:54:16.050871Z",
          "shell.execute_reply": "2023-02-19T23:54:16.048638Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.044531Z"
        },
        "id": "q2RL4VMyughp",
        "outputId": "9c40496d-cc21-4702-fb68-0a3909d014ab",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' а пять лет спустя был избран на второй срок. На посту президента в 2005 году его сменил Сергей Багапш. В ходе грузино-абхазского вооруженного конфликта Ардзинба руководил государственным комитетом обороны. Пост президента он занял в 1994 году',\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Каждому предложению (названию товара) теперь соответсвует не название категории, а её индекс:\n",
        "sentences[22], labels[22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.052063Z",
          "iopub.status.busy": "2023-02-19T23:54:16.051859Z",
          "iopub.status.idle": "2023-02-19T23:54:16.057221Z",
          "shell.execute_reply": "2023-02-19T23:54:16.056638Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.052037Z"
        },
        "id": "ebipCQUFukG2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Проверим, что все данные корректны\n",
        "assert len(sentences) == len(labels) == df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.058530Z",
          "iopub.status.busy": "2023-02-19T23:54:16.058242Z",
          "iopub.status.idle": "2023-02-19T23:54:16.271320Z",
          "shell.execute_reply": "2023-02-19T23:54:16.270815Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.058502Z"
        },
        "id": "6bLlupUcumwY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sentences = ['[CLS] ' + sentence + ' [SEP]' for sentence in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.272422Z",
          "iopub.status.busy": "2023-02-19T23:54:16.272171Z",
          "iopub.status.idle": "2023-02-19T23:54:16.315989Z",
          "shell.execute_reply": "2023-02-19T23:54:16.315487Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.272402Z"
        },
        "id": "RmDoRwT7uq0f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_sentences, test_sentences, train_category, test_category = train_test_split(sentences, labels, test_size=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.317120Z",
          "iopub.status.busy": "2023-02-19T23:54:16.316885Z",
          "iopub.status.idle": "2023-02-19T23:54:16.321677Z",
          "shell.execute_reply": "2023-02-19T23:54:16.321014Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.317097Z"
        },
        "id": "8lOPCZhHuuO2",
        "outputId": "93bf39f1-8843-44d4-b54b-2dfdc31a6a60",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104475, 525)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "len(train_sentences), len(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.322608Z",
          "iopub.status.busy": "2023-02-19T23:54:16.322450Z",
          "iopub.status.idle": "2023-02-19T23:54:19.994052Z",
          "shell.execute_reply": "2023-02-19T23:54:19.993482Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.322590Z"
        },
        "id": "5duuGlNYuwxU",
        "outputId": "33323fd0-f29c-4d4f-be39-f51c559373b3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Bert/Out_Bert_Finetuned were not used when initializing BertForMaskedLM: ['taskmodels_dict.clas.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.query.weight', 'encoder.encoder.layer.11.output.LayerNorm.bias', 'encoder.encoder.layer.1.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.encoder.layer.8.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.encoder.layer.11.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.dense.bias', 'encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.output.dense.weight', 'encoder.encoder.layer.4.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.key.bias', 'encoder.encoder.layer.3.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.self.key.bias', 'encoder.encoder.layer.5.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.key.weight', 'encoder.encoder.layer.9.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.encoder.layer.11.intermediate.dense.weight', 'encoder.encoder.layer.2.attention.self.query.bias', 'encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.key.bias', 'encoder.encoder.layer.9.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.value.bias', 'encoder.encoder.layer.1.intermediate.dense.bias', 'encoder.encoder.layer.1.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.encoder.layer.8.attention.self.value.weight', 'encoder.encoder.layer.10.attention.self.key.bias', 'encoder.encoder.layer.7.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.encoder.layer.1.attention.self.key.weight', 'encoder.encoder.layer.6.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.value.weight', 'encoder.encoder.layer.5.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.dense.weight', 'encoder.encoder.layer.4.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.encoder.layer.6.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.output.dense.weight', 'encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.query.bias', 'encoder.encoder.layer.3.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.dense.weight', 'taskmodels_dict.clas.classifier.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.value.bias', 'encoder.encoder.layer.3.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.encoder.layer.3.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.query.bias', 'encoder.encoder.layer.5.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.encoder.layer.6.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.value.bias', 'encoder.encoder.layer.7.attention.self.key.weight', 'encoder.encoder.layer.0.attention.self.key.bias', 'taskmodels_dict.rumed.classifier.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.value.bias', 'encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.query.bias', 'encoder.encoder.layer.11.attention.self.value.bias', 'encoder.encoder.layer.5.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.value.bias', 'encoder.encoder.layer.1.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.encoder.layer.0.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.encoder.layer.11.attention.self.value.weight', 'taskmodels_dict.clas.bert.embeddings.LayerNorm.weight', 'encoder.encoder.layer.7.attention.self.query.weight', 'encoder.encoder.layer.6.output.dense.weight', 'taskmodels_dict.clas.bert.embeddings.token_type_embeddings.weight', 'encoder.encoder.layer.5.attention.output.dense.weight', 'encoder.encoder.layer.4.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.encoder.layer.9.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.encoder.layer.10.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.value.weight', 'encoder.encoder.layer.0.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.key.weight', 'encoder.encoder.layer.9.intermediate.dense.weight', 'encoder.encoder.layer.5.attention.self.key.weight', 'encoder.encoder.layer.4.output.LayerNorm.bias', 'encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.encoder.layer.3.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.query.weight', 'encoder.encoder.layer.1.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.value.bias', 'encoder.encoder.layer.2.intermediate.dense.weight', 'encoder.encoder.layer.3.output.LayerNorm.weight', 'taskmodels_dict.rumed.classifier.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.encoder.layer.9.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.key.bias', 'encoder.encoder.layer.7.intermediate.dense.bias', 'encoder.encoder.layer.9.attention.self.value.bias', 'encoder.encoder.layer.5.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.encoder.layer.11.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.output.dense.bias', 'encoder.encoder.layer.8.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.value.weight', 'encoder.encoder.layer.7.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.query.weight', 'encoder.encoder.layer.0.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.key.bias', 'encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.encoder.layer.8.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.encoder.layer.6.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.encoder.layer.0.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.key.weight', 'encoder.encoder.layer.1.intermediate.dense.weight', 'encoder.encoder.layer.2.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.dense.bias', 'encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.encoder.layer.11.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.key.weight', 'encoder.encoder.layer.7.output.dense.bias', 'encoder.encoder.layer.3.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.key.bias', 'encoder.encoder.layer.10.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.query.weight', 'encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.encoder.layer.11.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.encoder.layer.5.output.dense.bias', 'encoder.encoder.layer.11.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.encoder.layer.4.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.output.dense.bias', 'encoder.encoder.layer.9.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.encoder.layer.6.output.LayerNorm.bias', 'encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.embeddings.token_type_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.value.weight', 'encoder.encoder.layer.11.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.encoder.layer.2.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.encoder.layer.3.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.value.weight', 'encoder.encoder.layer.4.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.encoder.layer.7.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.query.weight', 'encoder.encoder.layer.9.output.dense.bias', 'encoder.encoder.layer.3.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.key.bias', 'encoder.encoder.layer.11.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.encoder.layer.9.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.key.weight', 'encoder.encoder.layer.8.attention.output.dense.weight', 'encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.encoder.layer.6.attention.self.query.bias', 'encoder.encoder.layer.10.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.key.weight', 'encoder.encoder.layer.5.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.encoder.layer.1.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.encoder.layer.8.attention.self.value.bias', 'encoder.encoder.layer.10.attention.self.value.weight', 'encoder.encoder.layer.2.output.dense.weight', 'encoder.encoder.layer.1.attention.output.dense.bias', 'encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.embeddings.word_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.key.weight', 'encoder.encoder.layer.11.output.dense.weight', 'encoder.encoder.layer.1.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.query.bias', 'encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.query.weight', 'taskmodels_dict.clas.classifier.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.key.weight', 'encoder.encoder.layer.2.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.encoder.layer.8.attention.self.query.bias', 'encoder.encoder.layer.1.output.dense.weight', 'encoder.encoder.layer.10.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.encoder.layer.10.output.dense.bias', 'encoder.embeddings.LayerNorm.weight', 'encoder.encoder.layer.0.intermediate.dense.bias', 'encoder.encoder.layer.8.output.LayerNorm.bias', 'encoder.encoder.layer.2.output.dense.bias', 'encoder.encoder.layer.6.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.encoder.layer.9.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.query.bias', 'encoder.embeddings.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.encoder.layer.0.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.embeddings.token_type_embeddings.weight', 'encoder.embeddings.position_ids', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.embeddings.LayerNorm.bias', 'encoder.encoder.layer.5.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.output.dense.bias', 'encoder.encoder.layer.8.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.encoder.layer.3.attention.output.dense.bias', 'encoder.encoder.layer.3.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.encoder.layer.7.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.6.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.encoder.layer.4.output.dense.bias', 'encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.encoder.layer.8.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.value.bias', 'encoder.encoder.layer.5.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.encoder.layer.6.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.query.weight', 'encoder.encoder.layer.9.attention.self.query.bias', 'encoder.encoder.layer.10.attention.self.key.weight', 'encoder.encoder.layer.9.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.dense.weight', 'encoder.encoder.layer.0.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.encoder.layer.0.output.LayerNorm.weight', 'encoder.encoder.layer.10.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.encoder.layer.2.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.dense.bias', 'encoder.encoder.layer.1.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.encoder.layer.7.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.key.bias', 'encoder.encoder.layer.10.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.self.query.weight', 'encoder.encoder.layer.1.attention.self.key.bias', 'encoder.encoder.layer.0.attention.self.value.bias', 'encoder.encoder.layer.10.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.output.dense.weight', 'encoder.encoder.layer.8.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.encoder.layer.10.output.dense.weight', 'encoder.encoder.layer.9.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.key.weight', 'encoder.encoder.layer.3.output.LayerNorm.bias', 'encoder.encoder.layer.6.intermediate.dense.weight', 'encoder.encoder.layer.5.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.output.dense.bias', 'encoder.encoder.layer.6.attention.output.dense.weight', 'encoder.encoder.layer.8.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.query.weight', 'encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.encoder.layer.7.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.query.bias', 'taskmodels_dict.clas.bert.embeddings.position_ids', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.key.weight', 'encoder.encoder.layer.7.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.encoder.layer.5.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.output.dense.weight', 'encoder.encoder.layer.2.attention.self.value.weight', 'encoder.encoder.layer.0.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.dense.bias', 'encoder.encoder.layer.9.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.embeddings.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.encoder.layer.7.attention.output.dense.weight', 'encoder.encoder.layer.2.attention.output.dense.weight', 'encoder.encoder.layer.4.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.dense.bias', 'encoder.encoder.layer.3.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.encoder.layer.1.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.value.bias', 'encoder.encoder.layer.2.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.encoder.layer.6.output.dense.bias', 'encoder.encoder.layer.11.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.output.dense.weight', 'encoder.encoder.layer.11.attention.output.dense.weight', 'encoder.embeddings.position_embeddings.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.intermediate.dense.bias', 'taskmodels_dict.clas.bert.embeddings.position_embeddings.weight', 'encoder.embeddings.word_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.encoder.layer.4.intermediate.dense.bias', 'encoder.encoder.layer.4.attention.self.key.weight', 'encoder.encoder.layer.2.attention.output.dense.bias', 'encoder.encoder.layer.8.output.dense.weight', 'taskmodels_dict.rumed.bert.embeddings.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.key.weight', 'encoder.encoder.layer.6.attention.self.query.weight', 'encoder.encoder.layer.10.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.embeddings.position_ids', 'encoder.encoder.layer.10.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.encoder.layer.5.attention.self.value.bias', 'taskmodels_dict.rumed.bert.embeddings.position_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.encoder.layer.6.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.encoder.layer.2.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.encoder.layer.0.attention.self.query.weight', 'encoder.encoder.layer.7.output.dense.weight', 'encoder.encoder.layer.7.output.LayerNorm.weight', 'encoder.encoder.layer.3.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.encoder.layer.2.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.key.bias', 'encoder.encoder.layer.8.intermediate.dense.bias', 'taskmodels_dict.clas.bert.embeddings.word_embeddings.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at /content/drive/MyDrive/Bert/Out_Bert_Finetuned and are newly initialized: ['encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('\"Out_Bert_Pretrained/checkpoint-2500\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:19.995415Z",
          "iopub.status.busy": "2023-02-19T23:54:19.995120Z",
          "iopub.status.idle": "2023-02-20T00:05:47.471224Z",
          "shell.execute_reply": "2023-02-20T00:05:47.470713Z",
          "shell.execute_reply.started": "2023-02-19T23:54:19.995380Z"
        },
        "id": "ydwWyruWvSE5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:05:47.475306Z",
          "iopub.status.busy": "2023-02-20T00:05:47.474926Z",
          "iopub.status.idle": "2023-02-20T00:05:47.480072Z",
          "shell.execute_reply": "2023-02-20T00:05:47.479479Z",
          "shell.execute_reply.started": "2023-02-20T00:05:47.475282Z"
        },
        "id": "zudXX-SovVEf",
        "outputId": "68de3493-e701-4b60-b329-6ea16d2e3fba",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'р', '##о', '##с', '##с', '##ия', 'з', '##а', '##б', '##л', '##о', '##к', '##и', '##р', '##ов', '##а', '##л', '##а', 'р', '##е', '##з', '##о', '##л', '##ю', '##ц', '##и', '##ю', 'с', '##ов', '##б', '##е', '##з', '##а', 'о', '##о', '##н', 'п', '##о', 'к', '##р', '##ы', '##м', '##у', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# Посмотрим, что получилось\n",
        "print(tokenized_texts[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:05:47.481100Z",
          "iopub.status.busy": "2023-02-20T00:05:47.480905Z",
          "iopub.status.idle": "2023-02-20T00:06:57.787465Z",
          "shell.execute_reply": "2023-02-20T00:06:57.786886Z",
          "shell.execute_reply.started": "2023-02-20T00:05:47.481075Z"
        },
        "id": "TMJxzEplvZhM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ииндексы токенов\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:06:57.788628Z",
          "iopub.status.busy": "2023-02-20T00:06:57.788352Z",
          "iopub.status.idle": "2023-02-20T00:07:01.536542Z",
          "shell.execute_reply": "2023-02-20T00:07:01.535926Z",
          "shell.execute_reply.started": "2023-02-20T00:06:57.788601Z"
        },
        "id": "sYwnpHAZvbaV",
        "outputId": "ad195fd8-f15f-44f6-ed47-458788462f7f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.8903e+04, 8.5339e+04, 1.3000e+02, 4.5000e+01, 2.3000e+01,\n",
              "        1.6000e+01, 6.0000e+00, 8.0000e+00, 1.0000e+00, 4.0000e+00]),\n",
              " array([  5. ,  39.2,  73.4, 107.6, 141.8, 176. , 210.2, 244.4, 278.6,\n",
              "        312.8, 347. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Соберём все размеры последовательностей\n",
        "lenths = [len(sent) for sent in tokenized_texts]\n",
        "# Посмотрим, как они распределяются\n",
        "plt.hist(lenths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:01.539326Z",
          "iopub.status.busy": "2023-02-20T00:07:01.539167Z",
          "iopub.status.idle": "2023-02-20T00:07:02.072563Z",
          "shell.execute_reply": "2023-02-20T00:07:02.071850Z",
          "shell.execute_reply.started": "2023-02-20T00:07:01.539307Z"
        },
        "id": "obLVv2Qzvd4H",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Выравниваем датасет. Возьмём размер, равный 24\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    # максимальная длина предложения\n",
        "    maxlen=24,\n",
        "    dtype='long',\n",
        "    truncating='post',\n",
        "    padding='post'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:02.074105Z",
          "iopub.status.busy": "2023-02-20T00:07:02.073870Z",
          "iopub.status.idle": "2023-02-20T00:07:02.078592Z",
          "shell.execute_reply": "2023-02-20T00:07:02.077983Z",
          "shell.execute_reply.started": "2023-02-20T00:07:02.074080Z"
        },
        "id": "7nwOAQxkvf1f",
        "outputId": "d3a7010a-424a-4ef7-f8b3-f51e0a40d1fd",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  1195, 14150, 29747, 29747, 23483,  1187, 10260, 29740,\n",
              "       29436, 14150, 23925, 10325, 16856, 19259, 10260, 29436, 10260,\n",
              "        1195, 15290, 29744, 14150, 29436, 29757])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "\n",
        "# Вот, что у нас в результате получилось\n",
        "# Как видно, в этом примере меньше 24 токенов, поэтому в конец был добавлен паддинг\n",
        "input_ids[42]\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:02.080058Z",
          "iopub.status.busy": "2023-02-20T00:07:02.079487Z",
          "iopub.status.idle": "2023-02-20T00:07:03.154395Z",
          "shell.execute_reply": "2023-02-20T00:07:03.153888Z",
          "shell.execute_reply.started": "2023-02-20T00:07:02.080033Z"
        },
        "id": "fRblzCWLvij_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# Создадим маску внимания для каждого сэмпла обучающей выборки.\n",
        "# единицами отметим те токены, которые нужно учитывать при обучении и вычислении градиентов,\n",
        "# нулями - те, которые следует пропустить.\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.155480Z",
          "iopub.status.busy": "2023-02-20T00:07:03.155237Z",
          "iopub.status.idle": "2023-02-20T00:07:03.159357Z",
          "shell.execute_reply": "2023-02-20T00:07:03.158710Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.155456Z"
        },
        "id": "PnHS4sGpvjxv",
        "outputId": "b62dfe35-c681-460f-b675-ab4a8c39315c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(attention_masks[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.160532Z",
          "iopub.status.busy": "2023-02-20T00:07:03.160112Z",
          "iopub.status.idle": "2023-02-20T00:07:03.164266Z",
          "shell.execute_reply": "2023-02-20T00:07:03.163669Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.160496Z"
        },
        "id": "6QNhQ4kivmNM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# каждая маска соответсвует своей последовательности\n",
        "assert len(input_ids[42]) == len(attention_masks[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.165421Z",
          "iopub.status.busy": "2023-02-20T00:07:03.165127Z",
          "iopub.status.idle": "2023-02-20T00:07:03.221463Z",
          "shell.execute_reply": "2023-02-20T00:07:03.220895Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.165389Z"
        },
        "id": "Nh28tQ5jvniL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_category, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.222780Z",
          "iopub.status.busy": "2023-02-20T00:07:03.222409Z",
          "iopub.status.idle": "2023-02-20T00:07:03.227490Z",
          "shell.execute_reply": "2023-02-20T00:07:03.226925Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.222746Z"
        },
        "id": "_CyXsiTJvqaC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "assert len(train_inputs) == len(train_labels) == len(train_masks)\n",
        "assert len(validation_inputs) == len(validation_labels) == len(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.228360Z",
          "iopub.status.busy": "2023-02-20T00:07:03.228212Z",
          "iopub.status.idle": "2023-02-20T00:07:03.460335Z",
          "shell.execute_reply": "2023-02-20T00:07:03.459784Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.228342Z"
        },
        "id": "BZjiYOzbvsI8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.461633Z",
          "iopub.status.busy": "2023-02-20T00:07:03.461378Z",
          "iopub.status.idle": "2023-02-20T00:07:03.466425Z",
          "shell.execute_reply": "2023-02-20T00:07:03.465906Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.461601Z"
        },
        "id": "p8CZ2SrnwKzp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.469610Z",
          "iopub.status.busy": "2023-02-20T00:07:03.469057Z",
          "iopub.status.idle": "2023-02-20T00:07:03.475463Z",
          "shell.execute_reply": "2023-02-20T00:07:03.474984Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.469584Z"
        },
        "id": "kDAfR81svusf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# специальная обёртка для работы с Тензор-датасетами, в Pytorch есть и другие,\n",
        "# также можно и свою обёртку написать, для нашей же задачи вполне хватит уже существующих\n",
        "# в библиотеке инструментов. Используя их мы существенно сокращаем свой код.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    # Данные по батчам разбиваем произвольно с помощью RandomSampler\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=64\n",
        ")\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.476428Z",
          "iopub.status.busy": "2023-02-20T00:07:03.476235Z",
          "iopub.status.idle": "2023-02-20T00:07:03.553985Z",
          "shell.execute_reply": "2023-02-20T00:07:03.553514Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.476408Z"
        },
        "id": "-KI9-DRwwPaa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(\"Out_Bert_Pretrained/checkpoint-2500\",\n",
        "                                    num_labels=len(category_index),\n",
        "                                    id2label=category_index_reverce,\n",
        "                                    label2id=category_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.555252Z",
          "iopub.status.busy": "2023-02-20T00:07:03.555030Z",
          "iopub.status.idle": "2023-02-20T00:07:04.173838Z",
          "shell.execute_reply": "2023-02-20T00:07:04.173271Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.555223Z"
        },
        "id": "6g_UTEyVwa6J",
        "tags": [],
        "outputId": "a906c5d3-0838-4854-8d62-645eefb40573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#Загружаем модель, передаём ей наш конфиг\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Out_Bert_Pretrained/checkpoint-2500\", config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:04.175012Z",
          "iopub.status.busy": "2023-02-20T00:07:04.174782Z"
        },
        "id": "0yYqD7GfwlXZ",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4f2b9a-f19c-4a61-b01c-0258c17eae09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(2048, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Отправим на видеокарту, заодно посмотрим архитектуру нашего Берта\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HslZLAcVwqlk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Гипепараметры модели. Их можно изменять\n",
        "param_optimizer = list(model.named_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk-She3FwuOB",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bdd3cb-0ee5-4bf0-dc95-86476d5eb4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Можно посмотреть или изменить. Но нам этого не нужно, инициализируем лишь функцию\n",
        "# оптимизации. В качестве оптимизатора будем использовать оптимизированный \n",
        "# Adam (adaptive moment estimation)\n",
        "# for name, _ in param_optimizer:\n",
        "#     print(name)\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3HG-7maVGN1",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746999a9-a5de-4aa4-886a-8ad79ca6d266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(2048, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGQc6JBCwxLy",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154d9b34-a5e2-48f2-e0e1-8f35195f84be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Лосс на обучении: 1.5499461679231552\n",
            "CPU times: user 34.5 s, sys: 222 ms, total: 34.8 s\n",
            "Wall time: 34.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "    # Переводим данные на видеокарту\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Обнуляем градиенты\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Прогоняем данные по слоям нейросети\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss[0].item())  \n",
        "    \n",
        "    # Обратный прогон\n",
        "    loss[0].backward()\n",
        "    \n",
        "    # Шаг\n",
        "    optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "    train_loss += loss[0].item()\n",
        "    #print(f'Loss: {loss[0].item()}')\n",
        "print('*'*20)\n",
        "print(f'Лосс на обучении: {train_loss / len(train_dataloader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa64Tff2w3DP",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "213220e5-6909-4216-bde3-206e9af7a837"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# посмотрим, как обучалась наша модель\n",
        "plt.plot(train_loss_set)\n",
        "plt.title(\"Loss на обучении\")\n",
        "plt.xlabel(\"Батчи\")\n",
        "plt.ylabel(\"Потери\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cQUfdsDw6OC",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666129d7-4b1a-41f3-b76b-11b3048b0e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    \n",
        "    \n",
        "    # Вычислять градиенты не нужно\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем логиты и метки на CPU\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = label_ids #np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhJg3jUJKbJl",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba75891c-c024-4d71-863c-e8b1183e48ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Все       0.60      0.51      0.55      1472\n",
            "    Политика       0.60      0.62      0.61      1489\n",
            "    Общество       0.73      0.68      0.70      1555\n",
            "     Украина       0.34      0.30      0.32      1428\n",
            "Происшествия       0.47      0.48      0.48      1527\n",
            "Госэкономика       0.40      0.65      0.50      1524\n",
            "      Футбол       0.59      0.39      0.47      1453\n",
            "\n",
            "    accuracy                           0.52     10448\n",
            "   macro avg       0.53      0.52      0.52     10448\n",
            "weighted avg       0.53      0.52      0.52     10448\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(valid_labels, valid_preds, target_names=['Все', 'Политика', 'Общество', 'Украина', 'Происшествия',\n",
        "       'Госэкономика', 'Футбол']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbtrSGBvyGko"
      },
      "source": [
        "Сохранение и загрузка дообученной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qab-SpP1F1q4",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5b8406-9af3-4527-bd65-2fc8654418a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Bert/tokenizer_config.json',\n",
              " 'Bert/special_tokens_map.json',\n",
              " 'Bert/vocab.txt',\n",
              " 'Bert/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "model.save_pretrained('Bert')\n",
        "tokenizer.save_pretrained('Bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJWB4yDBF1q4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# config\n",
        "config = AutoConfig.from_pretrained('Bert')\n",
        "# tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('Bert', pad_to_max_length=True)\n",
        "# model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('Bert', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kdtb4JEF1q4",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae41761-c187-493c-96f2-951137d32979"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(2048, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g9EutO4F1q4",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7891e8de-dc7f-4081-9b00-d42495b864de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Название статьи: Главу Госкомстата Туркмении уволили за приукрашивание действительности\n",
            "Предсказанная категория: Все\n",
            "Истинная категория: Все\n",
            "\n",
            "Название статьи: Пенсии россиян снова «заморозят»\n",
            "Предсказанная категория: Общество\n",
            "Истинная категория: Госэкономика\n",
            "\n",
            "Название статьи: Граждане ЕС выбрали сторону в войне США с Россией\n",
            "Предсказанная категория: Общество\n",
            "Истинная категория: Политика\n",
            "\n",
            "Название статьи: ЦБ назвал причину сокращения резервов России \n",
            "Предсказанная категория: Госэкономика\n",
            "Истинная категория: Госэкономика\n",
            "\n",
            "Название статьи: Правозащитники подсчитали число современных рабов\n",
            "Предсказанная категория: Общество\n",
            "Истинная категория: Общество\n",
            "\n",
            "Название статьи: В России захотели взимать плату за вывоз мусора по-новому\n",
            "Предсказанная категория: Общество\n",
            "Истинная категория: Госэкономика\n",
            "\n",
            "Название статьи: Малайзия разочаровалась в расследовании гибели своего «Боинга» в Донбассе\n",
            "Предсказанная категория: Происшествия\n",
            "Истинная категория: Политика\n",
            "\n",
            "Название статьи: Лайнер со 150 пассажирами съехал со взлетной полосы в Париже\n",
            "Предсказанная категория: Происшествия\n",
            "Истинная категория: Происшествия\n",
            "\n",
            "Название статьи: Верховная Рада рассмотрит закон о защите двоечников\n",
            "Предсказанная категория: Украина\n",
            "Истинная категория: Все\n",
            "\n",
            "Название статьи: Определена отрасль с рекордным ростом зарплаты\n",
            "Предсказанная категория: Общество\n",
            "Истинная категория: Госэкономика\n",
            "\n",
            "CPU times: user 97 ms, sys: 2.03 ms, total: 99 ms\n",
            "Wall time: 97.3 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "# Выберем несколько случайных названий товаров\n",
        "skus = [randint(1, len(df)) for p in range(0, 10)]\n",
        "for sku in skus:\n",
        "    ground_truth = df.iloc[sku]['category_1']\n",
        "    sku_title = df.iloc[sku]['name']\n",
        "    tokens = tokenizer.encode(sku_title, add_special_tokens=True)\n",
        "    tokens_tensor = torch.tensor([tokens])\n",
        "    with torch.no_grad():\n",
        "        logits = model(tokens_tensor)\n",
        "    # Логиты по каждой категории\n",
        "    logits = logits[0].detach().numpy()\n",
        "    # Выбираем наиболее вероятную категорию товара\n",
        "    predicted_class = np.argmax(logits, axis=1)\n",
        "\n",
        "    print(f'Название статьи: {sku_title}')\n",
        "    print(f'Предсказанная категория: {category_index_reverce[predicted_class[0]]}')\n",
        "    print(f'Истинная категория: {ground_truth}')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZjXaCPF1q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta0Ymh2JF1q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF7eEAnyF1q5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "saturn (Python 3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}