{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yT57kOnchAU"
      },
      "source": [
        "Загружаем необходимые данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:46.287932Z",
          "iopub.status.busy": "2023-02-19T23:53:46.287635Z",
          "iopub.status.idle": "2023-02-19T23:53:49.117483Z",
          "shell.execute_reply": "2023-02-19T23:53:49.116676Z",
          "shell.execute_reply.started": "2023-02-19T23:53:46.287834Z"
        },
        "id": "bhIs5z1_uzTp",
        "outputId": "5b888739-1deb-40b5-8b0d-1e29a1510dc2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:49.119327Z",
          "iopub.status.busy": "2023-02-19T23:53:49.119045Z",
          "iopub.status.idle": "2023-02-19T23:53:51.987313Z",
          "shell.execute_reply": "2023-02-19T23:53:51.986714Z",
          "shell.execute_reply.started": "2023-02-19T23:53:49.119278Z"
        },
        "id": "lmYsdbdPF1qw",
        "outputId": "71948304-8167-406a-e990-fc3d37931aa8",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:51.988690Z",
          "iopub.status.busy": "2023-02-19T23:53:51.988409Z",
          "iopub.status.idle": "2023-02-19T23:53:54.716448Z",
          "shell.execute_reply": "2023-02-19T23:53:54.715843Z",
          "shell.execute_reply.started": "2023-02-19T23:53:51.988666Z"
        },
        "id": "OBEQfM7eF1qx",
        "outputId": "6ec89cc6-d9c4-4d84-8a0c-91fe51ffcb4d",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:53:54.717838Z",
          "iopub.status.busy": "2023-02-19T23:53:54.717582Z",
          "iopub.status.idle": "2023-02-19T23:54:07.908421Z",
          "shell.execute_reply": "2023-02-19T23:54:07.907907Z",
          "shell.execute_reply.started": "2023-02-19T23:53:54.717817Z"
        },
        "id": "7phFRstGrxYI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "import torch\n",
        "from torch.utils.data import (TensorDataset,\n",
        "                              DataLoader,\n",
        "                              RandomSampler)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForCausalLM,\n",
        "                          Trainer,\n",
        "                          TrainingArguments,\n",
        "                          TrainerCallback,\n",
        "                          AdamW,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:07.909845Z",
          "iopub.status.busy": "2023-02-19T23:54:07.909552Z",
          "iopub.status.idle": "2023-02-19T23:54:08.021570Z",
          "shell.execute_reply": "2023-02-19T23:54:08.020784Z",
          "shell.execute_reply.started": "2023-02-19T23:54:07.909813Z"
        },
        "id": "sP-aNRMQry7U",
        "outputId": "83528e4c-fe29-4bed-c623-7d2fa18a0e5f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "device = torch.device(device)\n",
        "\n",
        "print(device.type)\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:08.022851Z",
          "iopub.status.busy": "2023-02-19T23:54:08.022592Z",
          "iopub.status.idle": "2023-02-19T23:54:10.785031Z",
          "shell.execute_reply": "2023-02-19T23:54:10.784385Z",
          "shell.execute_reply.started": "2023-02-19T23:54:08.022830Z"
        },
        "id": "xOVjhJ8uF1qy",
        "outputId": "c100e249-bb75-421b-895a-ad98fa788c67",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.8/dist-packages (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install chardet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnybQK2VRNCf",
        "outputId": "2007279b-ee72-4ff1-a45b-124c6662e8ad"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:10.788335Z",
          "iopub.status.busy": "2023-02-19T23:54:10.788079Z",
          "iopub.status.idle": "2023-02-19T23:54:10.952168Z",
          "shell.execute_reply": "2023-02-19T23:54:10.951622Z",
          "shell.execute_reply.started": "2023-02-19T23:54:10.788311Z"
        },
        "id": "2QOtqSt3F1qy",
        "outputId": "667dd499-8ebc-411c-faa8-77fc96581db8",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoding': 'UTF-8-SIG', 'confidence': 1.0, 'language': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "import chardet\n",
        "with open('/content/drive/MyDrive/Bert/2 STEP (название).csv', 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(100000))\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:10.953303Z",
          "iopub.status.busy": "2023-02-19T23:54:10.953116Z",
          "iopub.status.idle": "2023-02-19T23:54:15.963491Z",
          "shell.execute_reply": "2023-02-19T23:54:15.962925Z",
          "shell.execute_reply.started": "2023-02-19T23:54:10.953273Z"
        },
        "id": "QZikC1XEr0je",
        "outputId": "5d3407b9-94fb-43b4-84d6-f6c33c3d9085",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Bert/2 STEP (название).csv', encoding='UTF-8-SIG', sep=';')\n",
        "# Размер нашей выборки\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:15.964895Z",
          "iopub.status.busy": "2023-02-19T23:54:15.964557Z",
          "iopub.status.idle": "2023-02-19T23:54:15.988189Z",
          "shell.execute_reply": "2023-02-19T23:54:15.987660Z",
          "shell.execute_reply.started": "2023-02-19T23:54:15.964857Z"
        },
        "id": "PBKA0cHgt6mL",
        "outputId": "14db2707-4b39-4c06-a179-33a37fcd1d8c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                                               name  \\\n",
              "82815        56756  СБУ отчиталась о поимке во Львове двух агентов...   \n",
              "100172       84606              Центробанк поднял курс евро на рубль    \n",
              "98641        59422  ФСБ пресекла попытку въезда в Крым цыган из За...   \n",
              "77174        53027  Российских следователей обстреляли с территори...   \n",
              "29854        12537  Главу ЦИК Латвии заподозрили в незаконной выпл...   \n",
              "\n",
              "          category_1  \n",
              "82815        Украина  \n",
              "100172  Госэкономика  \n",
              "98641        Украина  \n",
              "77174        Украина  \n",
              "29854            Все  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acd01e9a-49fc-4ba9-9184-825d7b27d95b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>category_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82815</th>\n",
              "      <td>56756</td>\n",
              "      <td>СБУ отчиталась о поимке во Львове двух агентов...</td>\n",
              "      <td>Украина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100172</th>\n",
              "      <td>84606</td>\n",
              "      <td>Центробанк поднял курс евро на рубль</td>\n",
              "      <td>Госэкономика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98641</th>\n",
              "      <td>59422</td>\n",
              "      <td>ФСБ пресекла попытку въезда в Крым цыган из За...</td>\n",
              "      <td>Украина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77174</th>\n",
              "      <td>53027</td>\n",
              "      <td>Российских следователей обстреляли с территори...</td>\n",
              "      <td>Украина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29854</th>\n",
              "      <td>12537</td>\n",
              "      <td>Главу ЦИК Латвии заподозрили в незаконной выпл...</td>\n",
              "      <td>Все</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acd01e9a-49fc-4ba9-9184-825d7b27d95b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acd01e9a-49fc-4ba9-9184-825d7b27d95b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acd01e9a-49fc-4ba9-9184-825d7b27d95b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:15.990409Z",
          "iopub.status.busy": "2023-02-19T23:54:15.989119Z",
          "iopub.status.idle": "2023-02-19T23:54:16.002621Z",
          "shell.execute_reply": "2023-02-19T23:54:16.002099Z",
          "shell.execute_reply.started": "2023-02-19T23:54:15.990383Z"
        },
        "id": "6HeuKAwIt-lK",
        "outputId": "ec1af2e2-86e7-40aa-d1f7-fe04d370990b",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Все', 'Украина', 'Футбол', 'Общество', 'Политика', 'Происшествия',\n",
              "       'Госэкономика'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "df.category_1.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.003614Z",
          "iopub.status.busy": "2023-02-19T23:54:16.003418Z",
          "iopub.status.idle": "2023-02-19T23:54:16.019050Z",
          "shell.execute_reply": "2023-02-19T23:54:16.018598Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.003594Z"
        },
        "id": "VaVzTbKbuZjn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Присвоим каждой категории индекс, чтобы подавать в модель\n",
        "category_index = {i[1]:i[0] for i in enumerate(df.category_1.unique())}\n",
        "# обратное преобразование - индекс метки в текст, этот словарь нам понадобится \n",
        "# после обучения для большей наглядности, чтобы видеть, к какой категории товар \n",
        "# отнесён моделью\n",
        "category_index_reverce = {i[0]:i[1] for i in enumerate(df.category_1.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.020200Z",
          "iopub.status.busy": "2023-02-19T23:54:16.019936Z",
          "iopub.status.idle": "2023-02-19T23:54:16.024561Z",
          "shell.execute_reply": "2023-02-19T23:54:16.024085Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.020169Z"
        },
        "id": "vLwLVkg3ubY_",
        "outputId": "b8a22713-a422-446d-e133-683c20ff6f2c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Все': 0,\n",
              " 'Украина': 1,\n",
              " 'Футбол': 2,\n",
              " 'Общество': 3,\n",
              " 'Политика': 4,\n",
              " 'Происшествия': 5,\n",
              " 'Госэкономика': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "category_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.025527Z",
          "iopub.status.busy": "2023-02-19T23:54:16.025335Z",
          "iopub.status.idle": "2023-02-19T23:54:16.029531Z",
          "shell.execute_reply": "2023-02-19T23:54:16.028917Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.025508Z"
        },
        "id": "O1dSD8gXF1q0",
        "outputId": "96d6cc3c-2e0c-4458-fda2-bf38d3aabe5f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Все',\n",
              " 1: 'Украина',\n",
              " 2: 'Футбол',\n",
              " 3: 'Общество',\n",
              " 4: 'Политика',\n",
              " 5: 'Происшествия',\n",
              " 6: 'Госэкономика'}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "category_index_reverce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.031136Z",
          "iopub.status.busy": "2023-02-19T23:54:16.030571Z",
          "iopub.status.idle": "2023-02-19T23:54:16.043366Z",
          "shell.execute_reply": "2023-02-19T23:54:16.042837Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.031103Z"
        },
        "id": "FCM9mjgHueWh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Переведём все метки датасета в числа\n",
        "sentences = df.name.values\n",
        "labels = [category_index[i] for i in df.category_1.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.044557Z",
          "iopub.status.busy": "2023-02-19T23:54:16.044296Z",
          "iopub.status.idle": "2023-02-19T23:54:16.050871Z",
          "shell.execute_reply": "2023-02-19T23:54:16.048638Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.044531Z"
        },
        "id": "q2RL4VMyughp",
        "outputId": "810718b4-339f-4225-869f-e5818a322cca",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' а пять лет спустя был избран на второй срок. На посту президента в 2005 году его сменил Сергей Багапш. В ходе грузино-абхазского вооруженного конфликта Ардзинба руководил государственным комитетом обороны. Пост президента он занял в 1994 году',\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "# Каждому предложению (названию товара) теперь соответсвует не название категории, а её индекс:\n",
        "sentences[22], labels[22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.052063Z",
          "iopub.status.busy": "2023-02-19T23:54:16.051859Z",
          "iopub.status.idle": "2023-02-19T23:54:16.057221Z",
          "shell.execute_reply": "2023-02-19T23:54:16.056638Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.052037Z"
        },
        "id": "ebipCQUFukG2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Проверим, что все данные корректны\n",
        "assert len(sentences) == len(labels) == df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.058530Z",
          "iopub.status.busy": "2023-02-19T23:54:16.058242Z",
          "iopub.status.idle": "2023-02-19T23:54:16.271320Z",
          "shell.execute_reply": "2023-02-19T23:54:16.270815Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.058502Z"
        },
        "id": "6bLlupUcumwY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sentences = ['[CLS] ' + sentence + ' [SEP]' for sentence in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.272422Z",
          "iopub.status.busy": "2023-02-19T23:54:16.272171Z",
          "iopub.status.idle": "2023-02-19T23:54:16.315989Z",
          "shell.execute_reply": "2023-02-19T23:54:16.315487Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.272402Z"
        },
        "id": "RmDoRwT7uq0f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_sentences, test_sentences, train_category, test_category = train_test_split(sentences, labels, test_size=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.317120Z",
          "iopub.status.busy": "2023-02-19T23:54:16.316885Z",
          "iopub.status.idle": "2023-02-19T23:54:16.321677Z",
          "shell.execute_reply": "2023-02-19T23:54:16.321014Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.317097Z"
        },
        "id": "8lOPCZhHuuO2",
        "outputId": "30819c0d-a855-4212-e335-7532ae80d8a3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104475, 525)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "len(train_sentences), len(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:16.322608Z",
          "iopub.status.busy": "2023-02-19T23:54:16.322450Z",
          "iopub.status.idle": "2023-02-19T23:54:19.994052Z",
          "shell.execute_reply": "2023-02-19T23:54:19.993482Z",
          "shell.execute_reply.started": "2023-02-19T23:54:16.322590Z"
        },
        "id": "5duuGlNYuwxU",
        "outputId": "42f834a9-5b81-44e1-f052-2756fbee592c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Bert/Out_Bert_Finetuned were not used when initializing BertForMaskedLM: ['taskmodels_dict.clas.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.query.weight', 'encoder.encoder.layer.11.output.LayerNorm.bias', 'encoder.encoder.layer.1.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.encoder.layer.8.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.encoder.layer.11.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.dense.bias', 'encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.output.dense.weight', 'encoder.encoder.layer.4.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.key.bias', 'encoder.encoder.layer.3.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.self.key.bias', 'encoder.encoder.layer.5.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.key.weight', 'encoder.encoder.layer.9.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.encoder.layer.11.intermediate.dense.weight', 'encoder.encoder.layer.2.attention.self.query.bias', 'encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.key.bias', 'encoder.encoder.layer.9.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.value.bias', 'encoder.encoder.layer.1.intermediate.dense.bias', 'encoder.encoder.layer.1.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.encoder.layer.8.attention.self.value.weight', 'encoder.encoder.layer.10.attention.self.key.bias', 'encoder.encoder.layer.7.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.encoder.layer.1.attention.self.key.weight', 'encoder.encoder.layer.6.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.value.weight', 'encoder.encoder.layer.5.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.dense.weight', 'encoder.encoder.layer.4.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.encoder.layer.6.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.output.dense.weight', 'encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.query.bias', 'encoder.encoder.layer.3.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.dense.weight', 'taskmodels_dict.clas.classifier.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.value.bias', 'encoder.encoder.layer.3.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.encoder.layer.3.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.query.bias', 'encoder.encoder.layer.5.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.encoder.layer.6.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.value.bias', 'encoder.encoder.layer.7.attention.self.key.weight', 'encoder.encoder.layer.0.attention.self.key.bias', 'taskmodels_dict.rumed.classifier.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.value.bias', 'encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.query.bias', 'encoder.encoder.layer.11.attention.self.value.bias', 'encoder.encoder.layer.5.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.value.bias', 'encoder.encoder.layer.1.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.encoder.layer.0.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.encoder.layer.11.attention.self.value.weight', 'taskmodels_dict.clas.bert.embeddings.LayerNorm.weight', 'encoder.encoder.layer.7.attention.self.query.weight', 'encoder.encoder.layer.6.output.dense.weight', 'taskmodels_dict.clas.bert.embeddings.token_type_embeddings.weight', 'encoder.encoder.layer.5.attention.output.dense.weight', 'encoder.encoder.layer.4.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.encoder.layer.9.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.encoder.layer.10.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.value.weight', 'encoder.encoder.layer.0.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.key.weight', 'encoder.encoder.layer.9.intermediate.dense.weight', 'encoder.encoder.layer.5.attention.self.key.weight', 'encoder.encoder.layer.4.output.LayerNorm.bias', 'encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.encoder.layer.3.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.query.weight', 'encoder.encoder.layer.1.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.value.bias', 'encoder.encoder.layer.2.intermediate.dense.weight', 'encoder.encoder.layer.3.output.LayerNorm.weight', 'taskmodels_dict.rumed.classifier.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.encoder.layer.9.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.key.bias', 'encoder.encoder.layer.7.intermediate.dense.bias', 'encoder.encoder.layer.9.attention.self.value.bias', 'encoder.encoder.layer.5.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.encoder.layer.11.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.output.dense.bias', 'encoder.encoder.layer.8.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.value.weight', 'encoder.encoder.layer.7.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.query.weight', 'encoder.encoder.layer.0.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.key.bias', 'encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.encoder.layer.8.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.encoder.layer.6.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.encoder.layer.0.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.key.weight', 'encoder.encoder.layer.1.intermediate.dense.weight', 'encoder.encoder.layer.2.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.dense.bias', 'encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.encoder.layer.11.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.key.weight', 'encoder.encoder.layer.7.output.dense.bias', 'encoder.encoder.layer.3.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.key.bias', 'encoder.encoder.layer.10.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.query.weight', 'encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.encoder.layer.11.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.encoder.layer.5.output.dense.bias', 'encoder.encoder.layer.11.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.encoder.layer.4.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.output.dense.bias', 'encoder.encoder.layer.9.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.encoder.layer.6.output.LayerNorm.bias', 'encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.embeddings.token_type_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.value.weight', 'encoder.encoder.layer.11.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.encoder.layer.2.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.encoder.layer.3.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.value.weight', 'encoder.encoder.layer.4.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.encoder.layer.7.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.query.weight', 'encoder.encoder.layer.9.output.dense.bias', 'encoder.encoder.layer.3.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.key.bias', 'encoder.encoder.layer.11.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.encoder.layer.9.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.key.weight', 'encoder.encoder.layer.8.attention.output.dense.weight', 'encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.encoder.layer.6.attention.self.query.bias', 'encoder.encoder.layer.10.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.key.weight', 'encoder.encoder.layer.5.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.encoder.layer.1.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.encoder.layer.8.attention.self.value.bias', 'encoder.encoder.layer.10.attention.self.value.weight', 'encoder.encoder.layer.2.output.dense.weight', 'encoder.encoder.layer.1.attention.output.dense.bias', 'encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.embeddings.word_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.self.key.weight', 'encoder.encoder.layer.11.output.dense.weight', 'encoder.encoder.layer.1.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.query.bias', 'encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.encoder.layer.0.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.query.weight', 'taskmodels_dict.clas.classifier.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.key.weight', 'encoder.encoder.layer.2.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.9.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.0.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.encoder.layer.8.attention.self.query.bias', 'encoder.encoder.layer.1.output.dense.weight', 'encoder.encoder.layer.10.attention.self.query.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.encoder.layer.10.output.dense.bias', 'encoder.embeddings.LayerNorm.weight', 'encoder.encoder.layer.0.intermediate.dense.bias', 'encoder.encoder.layer.8.output.LayerNorm.bias', 'encoder.encoder.layer.2.output.dense.bias', 'encoder.encoder.layer.6.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.encoder.layer.9.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.query.bias', 'encoder.embeddings.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.encoder.layer.0.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.embeddings.token_type_embeddings.weight', 'encoder.embeddings.position_ids', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.embeddings.LayerNorm.bias', 'encoder.encoder.layer.5.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.output.dense.bias', 'encoder.encoder.layer.8.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.encoder.layer.3.attention.output.dense.bias', 'encoder.encoder.layer.3.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.encoder.layer.7.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.6.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.encoder.layer.4.output.dense.bias', 'encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.encoder.layer.8.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.value.bias', 'encoder.encoder.layer.5.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.encoder.layer.6.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.attention.self.query.weight', 'encoder.encoder.layer.9.attention.self.query.bias', 'encoder.encoder.layer.10.attention.self.key.weight', 'encoder.encoder.layer.9.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.5.output.dense.weight', 'encoder.encoder.layer.0.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.encoder.layer.0.output.LayerNorm.weight', 'encoder.encoder.layer.10.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.encoder.layer.2.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.output.dense.bias', 'encoder.encoder.layer.1.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.encoder.layer.7.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.11.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.key.bias', 'encoder.encoder.layer.10.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.self.query.weight', 'encoder.encoder.layer.1.attention.self.key.bias', 'encoder.encoder.layer.0.attention.self.value.bias', 'encoder.encoder.layer.10.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.output.dense.weight', 'encoder.encoder.layer.8.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.encoder.layer.10.output.dense.weight', 'encoder.encoder.layer.9.attention.self.key.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.intermediate.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.6.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.5.attention.self.key.weight', 'encoder.encoder.layer.3.output.LayerNorm.bias', 'encoder.encoder.layer.6.intermediate.dense.weight', 'encoder.encoder.layer.5.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.output.dense.bias', 'encoder.encoder.layer.6.attention.output.dense.weight', 'encoder.encoder.layer.8.attention.self.key.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.self.query.weight', 'encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.encoder.layer.7.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.query.bias', 'taskmodels_dict.clas.bert.embeddings.position_ids', 'taskmodels_dict.rumed.bert.encoder.layer.0.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.key.weight', 'encoder.encoder.layer.7.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.6.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.encoder.layer.5.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.output.dense.weight', 'encoder.encoder.layer.2.attention.self.value.weight', 'encoder.encoder.layer.0.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.4.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.2.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.output.dense.bias', 'encoder.encoder.layer.9.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.2.intermediate.dense.bias', 'taskmodels_dict.rumed.bert.embeddings.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.encoder.layer.7.attention.output.dense.weight', 'encoder.encoder.layer.2.attention.output.dense.weight', 'encoder.encoder.layer.4.attention.self.value.bias', 'taskmodels_dict.clas.bert.encoder.layer.11.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.output.dense.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.output.dense.bias', 'encoder.encoder.layer.3.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.encoder.layer.1.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.value.bias', 'encoder.encoder.layer.2.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.10.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.encoder.layer.4.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.encoder.layer.6.output.dense.bias', 'encoder.encoder.layer.11.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.output.dense.weight', 'encoder.encoder.layer.11.attention.output.dense.weight', 'encoder.embeddings.position_embeddings.weight', 'taskmodels_dict.rumed.bert.encoder.layer.4.intermediate.dense.bias', 'taskmodels_dict.clas.bert.embeddings.position_embeddings.weight', 'encoder.embeddings.word_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.8.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.encoder.layer.4.intermediate.dense.bias', 'encoder.encoder.layer.4.attention.self.key.weight', 'encoder.encoder.layer.2.attention.output.dense.bias', 'encoder.encoder.layer.8.output.dense.weight', 'taskmodels_dict.rumed.bert.embeddings.LayerNorm.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.self.key.weight', 'encoder.encoder.layer.6.attention.self.query.weight', 'encoder.encoder.layer.10.intermediate.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.0.attention.self.key.bias', 'taskmodels_dict.clas.bert.encoder.layer.9.attention.output.dense.weight', 'taskmodels_dict.clas.bert.encoder.layer.5.intermediate.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.7.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.embeddings.position_ids', 'encoder.encoder.layer.10.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.11.attention.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.encoder.layer.5.attention.self.value.bias', 'taskmodels_dict.rumed.bert.embeddings.position_embeddings.weight', 'taskmodels_dict.clas.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.encoder.layer.6.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.encoder.layer.2.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.6.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.1.output.dense.bias', 'taskmodels_dict.clas.bert.encoder.layer.3.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.encoder.layer.0.attention.self.query.weight', 'encoder.encoder.layer.7.output.dense.weight', 'encoder.encoder.layer.7.output.LayerNorm.weight', 'encoder.encoder.layer.3.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.self.query.weight', 'taskmodels_dict.rumed.bert.encoder.layer.3.attention.self.query.bias', 'taskmodels_dict.rumed.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.encoder.layer.2.attention.self.value.bias', 'taskmodels_dict.rumed.bert.encoder.layer.6.attention.self.value.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.query.weight', 'taskmodels_dict.clas.bert.encoder.layer.1.attention.output.dense.weight', 'taskmodels_dict.rumed.bert.encoder.layer.9.attention.self.key.weight', 'taskmodels_dict.rumed.bert.encoder.layer.1.attention.self.value.weight', 'taskmodels_dict.clas.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'taskmodels_dict.rumed.bert.encoder.layer.7.attention.self.key.bias', 'encoder.encoder.layer.8.intermediate.dense.bias', 'taskmodels_dict.clas.bert.embeddings.word_embeddings.weight', 'taskmodels_dict.rumed.bert.encoder.layer.8.output.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at /content/drive/MyDrive/Bert/Out_Bert_Finetuned and are newly initialized: ['encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('/content/drive/MyDrive/Bert/Out_Bert_Finetuned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-19T23:54:19.995415Z",
          "iopub.status.busy": "2023-02-19T23:54:19.995120Z",
          "iopub.status.idle": "2023-02-20T00:05:47.471224Z",
          "shell.execute_reply": "2023-02-20T00:05:47.470713Z",
          "shell.execute_reply.started": "2023-02-19T23:54:19.995380Z"
        },
        "id": "ydwWyruWvSE5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:05:47.475306Z",
          "iopub.status.busy": "2023-02-20T00:05:47.474926Z",
          "iopub.status.idle": "2023-02-20T00:05:47.480072Z",
          "shell.execute_reply": "2023-02-20T00:05:47.479479Z",
          "shell.execute_reply.started": "2023-02-20T00:05:47.475282Z"
        },
        "id": "zudXX-SovVEf",
        "outputId": "2e39526a-1ff9-487c-ddd5-2049660f19d9",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'ч', '##л', '##е', '##н', '##ы', 'п', '##а', '##р', '##л', '##а', '##м', '##е', '##н', '##т', '##а', 'в', '##е', '##н', '##е', '##с', '##у', '##э', '##л', '##ы', 'п', '##о', '##д', '##р', '##а', '##л', '##и', '##с', '##ь', 'м', '##е', '##ж', '##д', '##у', 'с', '##о', '##б', '##о', '##и', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# Посмотрим, что получилось\n",
        "print(tokenized_texts[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:05:47.481100Z",
          "iopub.status.busy": "2023-02-20T00:05:47.480905Z",
          "iopub.status.idle": "2023-02-20T00:06:57.787465Z",
          "shell.execute_reply": "2023-02-20T00:06:57.786886Z",
          "shell.execute_reply.started": "2023-02-20T00:05:47.481075Z"
        },
        "id": "TMJxzEplvZhM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ииндексы токенов\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:06:57.788628Z",
          "iopub.status.busy": "2023-02-20T00:06:57.788352Z",
          "iopub.status.idle": "2023-02-20T00:07:01.536542Z",
          "shell.execute_reply": "2023-02-20T00:07:01.535926Z",
          "shell.execute_reply.started": "2023-02-20T00:06:57.788601Z"
        },
        "id": "sYwnpHAZvbaV",
        "outputId": "4d9beda6-70c2-473f-cfa3-a05f934a86d1",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.8903e+04, 8.5339e+04, 1.3100e+02, 4.5000e+01, 2.3000e+01,\n",
              "        1.5000e+01, 6.0000e+00, 8.0000e+00, 1.0000e+00, 4.0000e+00]),\n",
              " array([  5. ,  39.2,  73.4, 107.6, 141.8, 176. , 210.2, 244.4, 278.6,\n",
              "        312.8, 347. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW6klEQVR4nO3dcayd9X3f8fendiA0CbEJdxazrdlZrEYOWgjcEUeJoi1ejCFTzSQSgaZiRVY8DdiSadNqVmlukzAl01ZWpoTKLS52lsVQmgirMXVdQ1XtDwOXQABDqG8gFFuAb7GBplFInX73x/k5Obmce++5+Prce837JR2d5/k+v+c53/Po2p97nuc590lVIUl6c/ul2W5AkjT7DANJkmEgSTIMJEkYBpIkYOFsN/BGnX/++bVixYrZbkOS5o2HHnror6tqqNeyeRsGK1asYGRkZLbbkKR5I8mzEy3zMJEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkpjH30Cej1Zs+fasvfYPvvSJWXttSXOfnwwkSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkkSfYZDkPyQ5mOTxJN9I8tYkK5Pcn2Q0yR1Jzmpjz27zo235iq7t3NjqTyW5rKu+vtVGk2yZ6TcpSZrclGGQZCnw74HhqroQWABcDXwZuLmq3gMcBza1VTYBx1v95jaOJKvbeu8D1gNfTbIgyQLgK8DlwGrgmjZWkjQg/R4mWgick2Qh8MvA88DHgLva8h3AlW16Q5unLV+bJK2+q6peq6pngFHg0vYYraqnq+onwK42VpI0IFOGQVUdAf4H8Fd0QuAV4CHg5ao60YYdBpa26aXAc23dE238u7rr49aZqP46STYnGUkyMjY21s/7kyT1oZ/DRIvp/Ka+EviHwNvoHOYZuKraVlXDVTU8NDQ0Gy1I0hmpn8NE/wJ4pqrGqurvgG8CHwYWtcNGAMuAI236CLAcoC1/J/BSd33cOhPVJUkD0k8Y/BWwJskvt2P/a4EngPuAq9qYjcDdbXp3m6ctv7eqqtWvblcbrQRWAQ8ADwKr2tVJZ9E5ybz71N+aJKlfU97cpqruT3IX8B3gBPAwsA34NrAryRdb7ba2ym3A15KMAsfo/OdOVR1MciedIDkBXF9VPwVIcgOwl86VStur6uDMvUVJ0lT6utNZVW0Fto4rP03nSqDxY38MfHKC7dwE3NSjvgfY008vkqSZ5zeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRL93QP5V5I80vV4NcnnkpyXZF+SQ+15cRufJLckGU3yaJKLu7a1sY0/lGRjV/2SJI+1dW5pd1STJA3IlGFQVU9V1UVVdRFwCfAj4FvAFmB/Va0C9rd5gMvp3NJyFbAZuBUgyXl0bpDzQTo3xdl6MkDamM90rbd+Rt6dJKkv0z1MtBb4flU9C2wAdrT6DuDKNr0B2FkdB4BFSS4ALgP2VdWxqjoO7APWt2XnVtWBdq/knV3bkiQNwHTD4GrgG216SVU936ZfAJa06aXAc13rHG61yeqHe9RfJ8nmJCNJRsbGxqbZuiRpIn2HQZKzgF8F/nD8svYbfc1gXz1V1baqGq6q4aGhodP9cpL0pjGdTwaXA9+pqhfb/IvtEA/t+WirHwGWd623rNUmqy/rUZckDch0wuAafn6ICGA3cPKKoI3A3V31a9tVRWuAV9rhpL3AuiSL24njdcDetuzVJGvaVUTXdm1LkjQAC/sZlORtwMeBf9NV/hJwZ5JNwLPAp1p9D3AFMErnyqNPA1TVsSRfAB5s4z5fVcfa9HXA7cA5wD3tIUkakL7CoKr+FnjXuNpLdK4uGj+2gOsn2M52YHuP+ghwYT+9SJJmnt9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0GQZJFiW5K8n3kjyZ5ENJzkuyL8mh9ry4jU2SW5KMJnk0ycVd29nYxh9KsrGrfkmSx9o6t7Q7nkmSBqTfTwa/A/xJVb0XeD/wJLAF2F9Vq4D9bR4690pe1R6bgVsBkpwHbAU+CFwKbD0ZIG3MZ7rWW39qb0uSNB1ThkGSdwIfBW4DqKqfVNXLwAZgRxu2A7iyTW8AdlbHAWBRkguAy4B9VXWsqo4D+4D1bdm5VXWg3SVtZ9e2JEkD0M8ng5XAGPAHSR5O8vvtnshL2s3sAV4AlrTppcBzXesfbrXJ6od71F8nyeYkI0lGxsbG+mhdktSPfsJgIXAxcGtVfQD4W35+SAj42X2Pa+bb+0VVta2qhqtqeGho6HS/nCS9afQTBoeBw1V1f5u/i044vNgO8dCej7blR4DlXesva7XJ6st61CVJAzJlGFTVC8BzSX6lldYCTwC7gZNXBG0E7m7Tu4Fr21VFa4BX2uGkvcC6JIvbieN1wN627NUka9pVRNd2bUuSNAAL+xz374CvJzkLeBr4NJ0guTPJJuBZ4FNt7B7gCmAU+FEbS1UdS/IF4ME27vNVdaxNXwfcDpwD3NMekqQB6SsMquoRYLjHorU9xhZw/QTb2Q5s71EfAS7spxdJ0szzG8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiT7DIMkPkjyW5JEkI612XpJ9SQ6158WtniS3JBlN8miSi7u2s7GNP5RkY1f9krb90bZuZvqNSpImNp1PBv+8qi6qqpM3udkC7K+qVcD+Ng9wObCqPTYDt0InPICtwAeBS4GtJwOkjflM13rr3/A7kiRN26kcJtoA7GjTO4Aru+o7q+MAsCjJBcBlwL6qOlZVx4F9wPq27NyqOtDukraza1uSpAHoNwwK+NMkDyXZ3GpL2s3sAV4AlrTppcBzXesebrXJ6od71F8nyeYkI0lGxsbG+mxdkjSVvu6BDHykqo4k+QfAviTf615YVZWkZr69X1RV24BtAMPDw6f99STpzaKvTwZVdaQ9HwW+ReeY/4vtEA/t+WgbfgRY3rX6slabrL6sR12SNCBThkGStyV5x8lpYB3wOLAbOHlF0Ebg7ja9G7i2XVW0BnilHU7aC6xLsridOF4H7G3LXk2ypl1FdG3XtiRJA9DPYaIlwLfa1Z4Lgf9bVX+S5EHgziSbgGeBT7Xxe4ArgFHgR8CnAarqWJIvAA+2cZ+vqmNt+jrgduAc4J72kCQNyJRhUFVPA+/vUX8JWNujXsD1E2xrO7C9R30EuLCPfiVJp4HfQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJKYRBkkWJHk4yR+3+ZVJ7k8ymuSOJGe1+tltfrQtX9G1jRtb/akkl3XV17faaJItM/f2JEn9mM4ng88CT3bNfxm4uareAxwHNrX6JuB4q9/cxpFkNXA18D5gPfDVFjALgK8AlwOrgWvaWEnSgPQVBkmWAZ8Afr/NB/gYcFcbsgO4sk1vaPO05Wvb+A3Arqp6raqeoXOP5EvbY7Sqnq6qnwC72lhJ0oD0+8ngfwH/Gfj7Nv8u4OWqOtHmDwNL2/RS4DmAtvyVNv5n9XHrTFR/nSSbk4wkGRkbG+uzdUnSVKYMgyT/EjhaVQ8NoJ9JVdW2qhququGhoaHZbkeSzhgL+xjzYeBXk1wBvBU4F/gdYFGShe23/2XAkTb+CLAcOJxkIfBO4KWu+knd60xUlyQNwJSfDKrqxqpaVlUr6JwAvreq/jVwH3BVG7YRuLtN727ztOX3VlW1+tXtaqOVwCrgAeBBYFW7Oums9hq7Z+TdSZL60s8ng4n8OrAryReBh4HbWv024GtJRoFjdP5zp6oOJrkTeAI4AVxfVT8FSHIDsBdYAGyvqoOn0JckaZqmFQZV9efAn7fpp+lcCTR+zI+BT06w/k3ATT3qe4A90+lFkjRz/AayJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSaK/eyC/NckDSb6b5GCS32r1lUnuTzKa5I52lzLanczuaPX7k6zo2taNrf5Uksu66utbbTTJlpl/m5KkyfTzyeA14GNV9X7gImB9kjXAl4Gbq+o9wHFgUxu/CTje6je3cSRZTeeuZ+8D1gNfTbIgyQLgK8DlwGrgmjZWkjQg/dwDuarqh232Le1RwMeAu1p9B3Blm97Q5mnL1yZJq++qqteq6hlglM6d0i4FRqvq6ar6CbCrjZUkDUhf5wzab/CPAEeBfcD3gZer6kQbchhY2qaXAs8BtOWvAO/qro9bZ6J6rz42JxlJMjI2NtZP65KkPvQVBlX106q6CFhG5zf5957WribuY1tVDVfV8NDQ0Gy0IElnpGldTVRVLwP3AR8CFiVZ2BYtA4606SPAcoC2/J3AS931cetMVJckDUg/VxMNJVnUps8BPg48SScUrmrDNgJ3t+ndbZ62/N6qqla/ul1ttBJYBTwAPAisalcnnUXnJPPumXhzkqT+LJx6CBcAO9pVP78E3FlVf5zkCWBXki8CDwO3tfG3AV9LMgoco/OfO1V1MMmdwBPACeD6qvopQJIbgL3AAmB7VR2csXcoSZrSlGFQVY8CH+hRf5rO+YPx9R8Dn5xgWzcBN/Wo7wH29NGvJOk08BvIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIn+7nS2PMl9SZ5IcjDJZ1v9vCT7khxqz4tbPUluSTKa5NEkF3dta2MbfyjJxq76JUkea+vckiSn481Kknrr55PBCeA/VtVqYA1wfZLVwBZgf1WtAva3eYDL6dzSchWwGbgVOuEBbAU+SOemOFtPBkgb85mu9daf+luTJPVryjCoquer6jtt+m/o3P94KbAB2NGG7QCubNMbgJ3VcQBYlOQC4DJgX1Udq6rjwD5gfVt2blUdaPdK3tm1LUnSAEzrnEGSFXRugXk/sKSqnm+LXgCWtOmlwHNdqx1utcnqh3vUe73+5iQjSUbGxsam07okaRJ9h0GStwN/BHyuql7tXtZ+o68Z7u11qmpbVQ1X1fDQ0NDpfjlJetPoKwySvIVOEHy9qr7Zyi+2Qzy056OtfgRY3rX6slabrL6sR12SNCALpxrQruy5DXiyqn67a9FuYCPwpfZ8d1f9hiS76JwsfqWqnk+yF/hvXSeN1wE3VtWxJK8mWUPn8NO1wP+egfc2oRVbvn06Ny9J886UYQB8GPg14LEkj7Taf6ETAncm2QQ8C3yqLdsDXAGMAj8CPg3Q/tP/AvBgG/f5qjrWpq8DbgfOAe5pD0nSgEwZBlX1/4CJrvtf22N8AddPsK3twPYe9RHgwql6kSSdHn4DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRRxgk2Z7kaJLHu2rnJdmX5FB7XtzqSXJLktEkjya5uGudjW38oSQbu+qXJHmsrXNLu7OaJGmA+vlkcDuwflxtC7C/qlYB+9s8wOXAqvbYDNwKnfAAttK5DealwNau21/eCnyma73xryVJOs2mDIOq+gvg2LjyBmBHm94BXNlV31kdB4BFSS4ALgP2VdWxqjoO7APWt2XnVtWBdoe0nV3bkiQNyBs9Z7Ckqp5v0y8AS9r0UuC5rnGHW22y+uEedUnSAJ3yCeT2G33NQC9TSrI5yUiSkbGxsUG8pCS9KbzRMHixHeKhPR9t9SPA8q5xy1ptsvqyHvWeqmpbVQ1X1fDQ0NAbbF2SNN4bDYPdwMkrgjYCd3fVr21XFa0BXmmHk/YC65IsbieO1wF727JXk6xpVxFd27UtSdKALJxqQJJvAP8MOD/JYTpXBX0JuDPJJuBZ4FNt+B7gCmAU+BHwaYCqOpbkC8CDbdznq+rkSenr6FyxdA5wT3tIkgZoyjCoqmsmWLS2x9gCrp9gO9uB7T3qI8CFU/UhSTp9/AayJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxh8IgyfokTyUZTbJltvuRpDeTOREGSRYAXwEuB1YD1yRZPbtdSdKbx5S3vRyQS4HRqnoaIMkuYAPwxKx2dQZZseXbs/K6P/jSJ2bldSVNz1wJg6XAc13zh4EPjh+UZDOwuc3+MMlTfWz7fOCvT7nDwZpvPU/Yb7484E76d8bs4zlsvvU83/qF6ff8jyZaMFfCoC9VtQ3YNp11koxU1fBpaum0mG89z7d+Yf71PN/6hfnX83zrF2a25zlxzgA4Aizvml/WapKkAZgrYfAgsCrJyiRnAVcDu2e5J0l605gTh4mq6kSSG4C9wAJge1UdnKHNT+uw0hwx33qeb/3C/Ot5vvUL86/n+dYvzGDPqaqZ2pYkaZ6aK4eJJEmzyDCQJJ3ZYTAf/sRFkh8keSzJI0lGWu28JPuSHGrPi2e5x+1JjiZ5vKvWs8d03NL2+aNJLp4j/f5mkiNtPz+S5IquZTe2fp9Kctmg+209LE9yX5InkhxM8tlWn5P7eZJ+5+x+TvLWJA8k+W7r+bdafWWS+1tvd7SLWEhydpsfbctXzJF+b0/yTNc+vqjVT+1noqrOyAedE9HfB94NnAV8F1g923316PMHwPnjav8d2NKmtwBfnuUePwpcDDw+VY/AFcA9QIA1wP1zpN/fBP5Tj7Gr28/G2cDK9jOzYBZ6vgC4uE2/A/jL1tuc3M+T9Dtn93PbV29v028B7m/77k7g6lb/XeDftunrgN9t01cDd8yRfm8Hruox/pR+Js7kTwY/+xMXVfUT4OSfuJgPNgA72vQO4MpZ7IWq+gvg2LjyRD1uAHZWxwFgUZILBtNpxwT9TmQDsKuqXquqZ4BROj87A1VVz1fVd9r03wBP0vlm/pzcz5P0O5FZ389tX/2wzb6lPQr4GHBXq4/fxyf3/V3A2iQZULuT9TuRU/qZOJPDoNefuJjsh3W2FPCnSR5qf24DYElVPd+mXwCWzE5rk5qox7m8329oH5+3dx16m3P9tsMRH6Dzm+Cc38/j+oU5vJ+TLEjyCHAU2EfnE8rLVXWiR18/67ktfwV412z2W1Un9/FNbR/fnOTs8f0209rHZ3IYzBcfqaqL6fzF1uuTfLR7YXU+/83p63/nQ4/ArcA/Bi4Cngf+5+y201uStwN/BHyuql7tXjYX93OPfuf0fq6qn1bVRXT+ysGlwHtnuaVJje83yYXAjXT6/qfAecCvz8RrnclhMC/+xEVVHWnPR4Fv0fkBffHkx7v2fHT2OpzQRD3Oyf1eVS+2f1h/D/wePz9EMWf6TfIWOv+xfr2qvtnKc3Y/9+p3PuxngKp6GbgP+BCdwyknv4Db3dfPem7L3wm8NOBWgV/od307RFdV9RrwB8zQPj6Tw2DO/4mLJG9L8o6T08A64HE6fW5swzYCd89Oh5OaqMfdwLXtyoY1wCtdhzlmzbhjp/+Kzn6GTr9XtytHVgKrgAdmob8AtwFPVtVvdy2ak/t5on7n8n5OMpRkUZs+B/g4nXMd9wFXtWHj9/HJfX8VcG/7dDab/X6v65eD0Dm/0b2P3/jPxCDPjg/6Qefs+l/SOS74G7PdT4/+3k3nCovvAgdP9kjnuOR+4BDwZ8B5s9znN+h85P87OschN03UI50rGb7S9vljwPAc6fdrrZ9H2z+aC7rG/0br9yng8lnaxx+hcwjoUeCR9rhiru7nSfqds/sZ+CfAw623x4H/2urvphNMo8AfAme3+lvb/Ghb/u450u+9bR8/Dvwffn7F0Sn9TPjnKCRJZ/RhIklSnwwDSZJhIEkyDCRJGAaSJAwDSRKGgSQJ+P/WdLi3FrN7hwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Соберём все размеры последовательностей\n",
        "lenths = [len(sent) for sent in tokenized_texts]\n",
        "# Посмотрим, как они распределяются\n",
        "plt.hist(lenths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:01.539326Z",
          "iopub.status.busy": "2023-02-20T00:07:01.539167Z",
          "iopub.status.idle": "2023-02-20T00:07:02.072563Z",
          "shell.execute_reply": "2023-02-20T00:07:02.071850Z",
          "shell.execute_reply.started": "2023-02-20T00:07:01.539307Z"
        },
        "id": "obLVv2Qzvd4H",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Выравниваем датасет. Возьмём размер, равный 24\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    # максимальная длина предложения\n",
        "    maxlen=24,\n",
        "    dtype='long',\n",
        "    truncating='post',\n",
        "    padding='post'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:02.074105Z",
          "iopub.status.busy": "2023-02-20T00:07:02.073870Z",
          "iopub.status.idle": "2023-02-20T00:07:02.078592Z",
          "shell.execute_reply": "2023-02-20T00:07:02.077983Z",
          "shell.execute_reply.started": "2023-02-20T00:07:02.074080Z"
        },
        "id": "7nwOAQxkvf1f",
        "outputId": "3c1f7dea-1602-486c-9c92-8f3ad435b7da",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  1202, 29436, 15290, 18947, 29113,  1194, 10260, 16856,\n",
              "       29436, 10260, 29745, 15290, 18947, 22919, 10260,  1182, 15290,\n",
              "       18947, 15290, 29747, 29748, 29756, 29436])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "\n",
        "# Вот, что у нас в результате получилось\n",
        "# Как видно, в этом примере меньше 24 токенов, поэтому в конец был добавлен паддинг\n",
        "input_ids[42]\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:02.080058Z",
          "iopub.status.busy": "2023-02-20T00:07:02.079487Z",
          "iopub.status.idle": "2023-02-20T00:07:03.154395Z",
          "shell.execute_reply": "2023-02-20T00:07:03.153888Z",
          "shell.execute_reply.started": "2023-02-20T00:07:02.080033Z"
        },
        "id": "fRblzCWLvij_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# Создадим маску внимания для каждого сэмпла обучающей выборки.\n",
        "# единицами отметим те токены, которые нужно учитывать при обучении и вычислении градиентов,\n",
        "# нулями - те, которые следует пропустить.\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.155480Z",
          "iopub.status.busy": "2023-02-20T00:07:03.155237Z",
          "iopub.status.idle": "2023-02-20T00:07:03.159357Z",
          "shell.execute_reply": "2023-02-20T00:07:03.158710Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.155456Z"
        },
        "id": "PnHS4sGpvjxv",
        "outputId": "d06a83e0-271b-41fc-f223-5a57928883ea",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(attention_masks[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.160532Z",
          "iopub.status.busy": "2023-02-20T00:07:03.160112Z",
          "iopub.status.idle": "2023-02-20T00:07:03.164266Z",
          "shell.execute_reply": "2023-02-20T00:07:03.163669Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.160496Z"
        },
        "id": "6QNhQ4kivmNM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# каждая маска соответсвует своей последовательности\n",
        "assert len(input_ids[42]) == len(attention_masks[42])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.165421Z",
          "iopub.status.busy": "2023-02-20T00:07:03.165127Z",
          "iopub.status.idle": "2023-02-20T00:07:03.221463Z",
          "shell.execute_reply": "2023-02-20T00:07:03.220895Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.165389Z"
        },
        "id": "Nh28tQ5jvniL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_category, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.222780Z",
          "iopub.status.busy": "2023-02-20T00:07:03.222409Z",
          "iopub.status.idle": "2023-02-20T00:07:03.227490Z",
          "shell.execute_reply": "2023-02-20T00:07:03.226925Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.222746Z"
        },
        "id": "_CyXsiTJvqaC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "assert len(train_inputs) == len(train_labels) == len(train_masks)\n",
        "assert len(validation_inputs) == len(validation_labels) == len(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.228360Z",
          "iopub.status.busy": "2023-02-20T00:07:03.228212Z",
          "iopub.status.idle": "2023-02-20T00:07:03.460335Z",
          "shell.execute_reply": "2023-02-20T00:07:03.459784Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.228342Z"
        },
        "id": "BZjiYOzbvsI8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.461633Z",
          "iopub.status.busy": "2023-02-20T00:07:03.461378Z",
          "iopub.status.idle": "2023-02-20T00:07:03.466425Z",
          "shell.execute_reply": "2023-02-20T00:07:03.465906Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.461601Z"
        },
        "id": "p8CZ2SrnwKzp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.469610Z",
          "iopub.status.busy": "2023-02-20T00:07:03.469057Z",
          "iopub.status.idle": "2023-02-20T00:07:03.475463Z",
          "shell.execute_reply": "2023-02-20T00:07:03.474984Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.469584Z"
        },
        "id": "kDAfR81svusf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# специальная обёртка для работы с Тензор-датасетами, в Pytorch есть и другие,\n",
        "# также можно и свою обёртку написать, для нашей же задачи вполне хватит уже существующих\n",
        "# в библиотеке инструментов. Используя их мы существенно сокращаем свой код.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    # Данные по батчам разбиваем произвольно с помощью RandomSampler\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=64\n",
        ")\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.476428Z",
          "iopub.status.busy": "2023-02-20T00:07:03.476235Z",
          "iopub.status.idle": "2023-02-20T00:07:03.553985Z",
          "shell.execute_reply": "2023-02-20T00:07:03.553514Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.476408Z"
        },
        "id": "-KI9-DRwwPaa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(model,\n",
        "                                    num_labels=len(category_index),\n",
        "                                    id2label=category_index_reverce,\n",
        "                                    label2id=category_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:03.555252Z",
          "iopub.status.busy": "2023-02-20T00:07:03.555030Z",
          "iopub.status.idle": "2023-02-20T00:07:04.173838Z",
          "shell.execute_reply": "2023-02-20T00:07:04.173271Z",
          "shell.execute_reply.started": "2023-02-20T00:07:03.555223Z"
        },
        "id": "6g_UTEyVwa6J",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Загружаем модель, передаём ей наш конфиг\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T00:07:04.175012Z",
          "iopub.status.busy": "2023-02-20T00:07:04.174782Z"
        },
        "id": "0yYqD7GfwlXZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Отправим на видеокарту, заодно посмотрим архитектуру нашего Берта\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HslZLAcVwqlk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Гипепараметры модели. Их можно изменять\n",
        "param_optimizer = list(model.named_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk-She3FwuOB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Можно посмотреть или изменить. Но нам этого не нужно, инициализируем лишь функцию\n",
        "# оптимизации. В качестве оптимизатора будем использовать оптимизированный \n",
        "# Adam (adaptive moment estimation)\n",
        "# for name, _ in param_optimizer:\n",
        "#     print(name)\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3HG-7maVGN1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGQc6JBCwxLy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "    # Переводим данные на видеокарту\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Обнуляем градиенты\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Прогоняем данные по слоям нейросети\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss[0].item())  \n",
        "    \n",
        "    # Обратный прогон\n",
        "    loss[0].backward()\n",
        "    \n",
        "    # Шаг\n",
        "    optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "    train_loss += loss[0].item()\n",
        "    #print(f'Loss: {loss[0].item()}')\n",
        "print('*'*20)\n",
        "print(f'Лосс на обучении: {train_loss / len(train_dataloader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa64Tff2w3DP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# посмотрим, как обучалась наша модель\n",
        "plt.plot(train_loss_set)\n",
        "plt.title(\"Loss на обучении\")\n",
        "plt.xlabel(\"Батчи\")\n",
        "plt.ylabel(\"Потери\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cQUfdsDw6OC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%time\n",
        "\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    \n",
        "    \n",
        "    # Вычислять градиенты не нужно\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем логиты и метки на CPU\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = label_ids #np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhJg3jUJKbJl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(classification_report(valid_labels, valid_preds, target_names=['Все', 'Политика', 'Общество', 'Украина', 'Происшествия',\n",
        "       'Госэкономика', 'Футбол']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbtrSGBvyGko"
      },
      "source": [
        "Сохранение и загрузка дообученной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qab-SpP1F1q4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('Bert')\n",
        "tokenizer.save_pretrained('Bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJWB4yDBF1q4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# config\n",
        "config = AutoConfig.from_pretrained('Bert')\n",
        "# tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('Bert', pad_to_max_length=True)\n",
        "# model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('Bert', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kdtb4JEF1q4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g9EutO4F1q4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "# Выберем несколько случайных названий товаров\n",
        "skus = [randint(1, len(df)) for p in range(0, 10)]\n",
        "for sku in skus:\n",
        "    ground_truth = df.iloc[sku]['category_1']\n",
        "    sku_title = df.iloc[sku]['name']\n",
        "    tokens = tokenizer.encode(sku_title, add_special_tokens=True)\n",
        "    tokens_tensor = torch.tensor([tokens])\n",
        "    with torch.no_grad():\n",
        "        logits = model(tokens_tensor)\n",
        "    # Логиты по каждой категории\n",
        "    logits = logits[0].detach().numpy()\n",
        "    # Выбираем наиболее вероятную категорию товара\n",
        "    predicted_class = np.argmax(logits, axis=1)\n",
        "\n",
        "    print(f'Название статьи: {sku_title}')\n",
        "    print(f'Предсказанная категория: {category_index_reverce[predicted_class[0]]}')\n",
        "    print(f'Истинная категория: {ground_truth}')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZjXaCPF1q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta0Ymh2JF1q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF7eEAnyF1q5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "saturn (Python 3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}