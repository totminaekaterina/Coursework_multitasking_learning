{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEdOmkNC+6enOM4L4cEYDo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totminaekaterina/Coursework_multitasking_learning/blob/main/QG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CHP4_kuDOiu",
        "outputId": "0860014b-ced4-4400-9d35-c114d2ad6fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SentencePiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcNh7sU5IPbP",
        "outputId": "da6110bc-b167-4d0a-f560-96c1e607479a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "\n",
        "# Загрузка датасета\n",
        "with open('train.json', 'r', encoding='utf-8-sig') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "Zfm929xgGxUz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rut5-base-multitask\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"cointegrated/rut5-base-multitask\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGGvce17IdAu",
        "outputId": "270039f5-a877-4f04-d38e-2f339ce0804e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW"
      ],
      "metadata": {
        "id": "psWy_I_yJiuZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение параметров обучения\n",
        "num_epochs = 10\n",
        "batch_size = 4\n",
        "learning_rate = 3e-5"
      ],
      "metadata": {
        "id": "mCBFryS_IDro"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "AnOVgFNULkUT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-fwJ38xMYfM",
        "outputId": "f95f58bc-5e29-4728-f9e3-c928b2467aa6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение оптимизатора и функции потерь\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# Обучение модели\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = len(data) // batch_size\n",
        "\n",
        "    # добавленные строки\n",
        "    f1_score_total = 0.0\n",
        "    acc_total = 0.0\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch = data[i * batch_size: (i+1) * batch_size]\n",
        "\n",
        "        # Токенизация данных и генерация вопросов\n",
        "        input_sentences = [item['passage'] for item in batch]\n",
        "        target_questions = [item['question'] for item in batch]\n",
        "        input_tokens = tokenizer.batch_encode_plus(input_sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "        target_tokens = tokenizer.batch_encode_plus(target_questions, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "        # Подготовка входных данных\n",
        "        input_ids = input_tokens['input_ids'].to(device)\n",
        "        attention_mask = input_tokens['attention_mask'].to(device)\n",
        "        target_ids = target_tokens['input_ids'].to(device)\n",
        "        target_ids[target_ids == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        # Обнуление градиентов и вычисление предсказаний модели\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=target_ids)\n",
        "\n",
        "        # Расчет функции потерь и обновление весов\n",
        "        loss = outputs.loss\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # добавленные строки\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        f1_score_total += f1_score(target_ids.view(-1).cpu().numpy(), predictions.view(-1).cpu().numpy(), average='macro')\n",
        "        acc_total += accuracy_score(target_ids.view(-1).cpu().numpy(), predictions.view(-1).cpu().numpy())\n",
        "\n",
        "    print('Epoch:', epoch+1, '\\tLoss:', epoch_loss/num_batches, '\\tF1 Score:', f1_score_total/num_batches, '\\tAccuracy:', acc_total/num_batches)\n",
        "\n",
        "# Сохранение обученной модели\n",
        "model.save_pretrained('question_generation_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLr3Dc1KJmgO",
        "outputId": "8010ba82-55e6-4c02-b7bb-7be292c28576"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tLoss: 1.5903467690099022 \tF1 Score: 0.4832782734093054 \tAccuracy: 0.5638025941215289\n",
            "Epoch: 2 \tLoss: 0.9442548288087823 \tF1 Score: 0.6149415500739588 \tAccuracy: 0.6592435032086709\n",
            "Epoch: 3 \tLoss: 0.59163909305731 \tF1 Score: 0.7151062160071894 \tAccuracy: 0.7194329419660993\n",
            "Epoch: 4 \tLoss: 0.3658997725857341 \tF1 Score: 0.7936717967177362 \tAccuracy: 0.7626428663480311\n",
            "Epoch: 5 \tLoss: 0.23037898378953917 \tF1 Score: 0.8427806384795609 \tAccuracy: 0.7882159879224754\n",
            "Epoch: 6 \tLoss: 0.15507449073508142 \tF1 Score: 0.8710709438144962 \tAccuracy: 0.8020568602527078\n",
            "Epoch: 7 \tLoss: 0.10408216320485457 \tF1 Score: 0.8923608545167833 \tAccuracy: 0.8118036941864307\n",
            "Epoch: 8 \tLoss: 0.0743196296289316 \tF1 Score: 0.9050667039857796 \tAccuracy: 0.8180069809621445\n",
            "Epoch: 9 \tLoss: 0.0630970623397995 \tF1 Score: 0.9105401040325845 \tAccuracy: 0.8199626023097651\n",
            "Epoch: 10 \tLoss: 0.05112106864073141 \tF1 Score: 0.9131229454109415 \tAccuracy: 0.8212121849369416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFnpA54XSu4y",
        "outputId": "b30f46c2-ed2e-4323-aa33-8f0154d3599c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение обученной модели\n",
        "model.save_pretrained('/content/drive/MyDrive/Bert/question_generation_model_1')"
      ],
      "metadata": {
        "id": "F_cDpSGSwLuV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering"
      ],
      "metadata": {
        "id": "ES7mzXoxN97x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация токенизатора и модели\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained('/content/question_generation_model_1')"
      ],
      "metadata": {
        "id": "E5_YYU03PLUi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "-6KZsEEFVOGf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Bert/TrainOnlySentenceJson.json', 'r', encoding='utf-8-sig',) as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ51E19APJcU",
        "outputId": "d451c95a-c466-4808-991f-112d11f5fe3a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = [item['text'] for item in test_data]\n",
        "input_tokens = tokenizer.batch_encode_plus(input_sentences, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "VHHs3dgURLz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokens = model.generate(\n",
        "    input_ids=input_tokens['input_ids'].to('cpu'),\n",
        "    attention_mask=input_tokens['attention_mask'].to('cpu'),\n",
        "    max_length=50,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")"
      ],
      "metadata": {
        "id": "18tDLy4uQ0Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_questions = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output_tokens]"
      ],
      "metadata": {
        "id": "QZ8rER-xVsnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = []\n",
        "for i in range(len(test_data)):\n",
        "    output_data.append({'Sentence': test_data[i]['text'], 'Question': generated_questions[i]})"
      ],
      "metadata": {
        "id": "tKjb777EQ2RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Bert/output_data_big.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "pksV2WQEQ2kW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}