{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKmM0Qek8e9e"
   },
   "source": [
    "## Распознавание Именованных Сущностей с помощью библиотеки DeepPavlov\n",
    "\n",
    "Задачей Распознавания Именованных Сущностей (РИС) называется извлечение из текста таких объектов как имена, названия организаций, названия географических объектов. Данная задача как правило является компонентом в более крупной системе. Например, в диалоговой системе РИС может быть использован для выделения имени собеседника. В библиотеке [DeepPavlov](https://github.com/deepmipt/DeepPavlov) есть ряд моделей которые решают данную задачу. В данном notebook-е мы рассмотрим две модели решающие задачу РИС на русском языке: [BERT](https://arxiv.org/pdf/1810.04805.pdf), показывающий на данный момент наилучшее качество, и [Bi-LSTM-CRF](https://arxiv.org/pdf/1603.01360.pdf) - уступающий по метрикам, однако более быстрый baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-cExZYT8e9h"
   },
   "source": [
    "## Постановка задачи\n",
    "\n",
    "Задача РИС может быть поставлена следующим образом: для заданной последовательность слов (токенов) предсказать последовательность тагов (меток). Каждому входному токену сопоставляется таг из заданного множества тагов. Пример:\n",
    "\n",
    "    Алиса  в  Стране чудес\n",
    "     PER   O   LOC    LOC\n",
    "\n",
    "здесь PER - персона, LOC - локация. Однко, представленная разметка не позволяет разделять подряд идущие сущности. Для разделения таких сущностей используют префиксы B и I перед каждым тагом кроме O. Префикс B обозначает начало сущности, а I - продолжение. Тогда для примера выше будет следующая разметка:\n",
    "\n",
    "    Алиса  в  Стране чудес\n",
    "    B-PER  O  B-LOC  I-LOC\n",
    "\n",
    "Разметка с префиксами B и O - наиболее распространённый способ разметки данных. Данный тип разметки часто называют BIO или IOB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQlTNNRs8e9h"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Рассматриваемые в данном notebook-е модели были обучены на датасете [1]. Данный датасет содержит 1000 новостей в которых размечены персоны (PER), локации (LOC) и организации (ORG). В силу того, что обучающая выборка содержит только новостные данные смена типов распознаваемых текстов может существенно отразиться на качестве работы системы. Например, при использовании модели обученной на новостях переход к распознавания диалогов службы поддрежки может существенно снизить качество работы системы.\n",
    "\n",
    "1. Mozharova V., Loukachevitch N., Two-stage approach in Russian named entity recognition // International FRUCT Conference on Intelligence, Social Media and Web, ISMW FRUCT 2016. Saint-Petersburg; Russian Federation, DOI 10.1109/FRUCT.2016.7584769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf05kK918e9i"
   },
   "source": [
    "## Установка библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njjFl7bp8e9i",
    "outputId": "e2a22369-f378-4b92-fa67-f842e49a8a94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.2.2 requires fsspec, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RP7Ja5lN8e9j"
   },
   "source": [
    "## Установка зависимостей, спецефичных для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhkQtT358e9j",
    "outputId": "126e09f1-d326-405b-b3da-f6af7b629987",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf==0.7.*\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n",
      "Ignoring transformers: markers 'python_version < \"3.8\"' don't match your environment\n",
      "Collecting transformers==4.30.0\n",
      "  Downloading transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\n",
      "     ---------------------------------------- 0.0/113.6 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/113.6 kB ? eta -:--:--\n",
      "     ---------- -------------------------- 30.7/113.6 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------- ----------------------- 41.0/113.6 kB 326.8 kB/s eta 0:00:01\n",
      "     ------------------------------ ------ 92.2/113.6 kB 585.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 113.6/113.6 kB 662.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (3.9.1)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.0)\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.30.0)\n",
      "  Using cached safetensors-0.4.2-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from transformers==4.30.0) (4.64.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from tqdm>=4.27->transformers==4.30.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from requests->transformers==4.30.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from requests->transformers==4.30.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from requests->transformers==4.30.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\totmi\\anaconda\\envs\\diplom\\lib\\site-packages (from requests->transformers==4.30.0) (2024.2.2)\n",
      "Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
      "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/7.2 MB 3.6 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.2/7.2 MB 1.8 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.4/7.2 MB 2.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/7.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.9/7.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.3/7.2 MB 4.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.5/7.2 MB 5.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.5/7.2 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.5/7.2 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.8/7.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.0/7.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.0/7.2 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.6/7.2 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.8/7.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.0/7.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.0/7.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.6/7.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.1/7.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.6/7.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.1/7.2 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.6/7.2 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.1/7.2 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.2/7.2 MB 6.8 MB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Using cached safetensors-0.4.2-cp311-none-win_amd64.whl (269 kB)\n",
      "Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.6/3.5 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.0/3.5 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.6/3.5 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.1/3.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.5/3.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 11.1 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Installing collected packages: tokenizers, safetensors, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2024.3.1 huggingface-hub-0.22.2 safetensors-0.4.2 tokenizers-0.13.3 transformers-4.30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch<1.14.0,>=1.6.0 (from versions: 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2)\n",
      "ERROR: No matching distribution found for torch<1.14.0,>=1.6.0\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\totmi\\anaconda\\envs\\Diplom\\Lib\\site-packages\\deeppavlov\\__main__.py\", line 4, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\totmi\\anaconda\\envs\\Diplom\\Lib\\site-packages\\deeppavlov\\deep.py\", line 62, in main\n",
      "    install_from_config(pipeline_config_path)\n",
      "  File \"C:\\Users\\totmi\\anaconda\\envs\\Diplom\\Lib\\site-packages\\deeppavlov\\utils\\pip_wrapper\\pip_wrapper.py\", line 71, in install_from_config\n",
      "    install(r)\n",
      "  File \"C:\\Users\\totmi\\anaconda\\envs\\Diplom\\Lib\\site-packages\\deeppavlov\\utils\\pip_wrapper\\pip_wrapper.py\", line 36, in install\n",
      "    result = subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\totmi\\anaconda\\envs\\Diplom\\Lib\\subprocess.py\", line 413, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['C:\\\\Users\\\\totmi\\\\anaconda\\\\envs\\\\Diplom\\\\python.exe', '-m', 'pip', 'install', 'torch>=1.6.0,<1.14.0']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install ner_rus_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO81i0O28e9j"
   },
   "source": [
    "## Использование моделей\n",
    "\n",
    "### BERT\n",
    "\n",
    "BERT - сеть архитектуры Transformer предобученная на задаче Masked Language Modelling (MLM). Модель осуществляющая РИС использует [RuBERT](https://arxiv.org/abs/1905.07213) предобученный на русском языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EtjNtl3i8e9j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 18:55:26.175 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/v1/ner/ner_rus_bert_torch_new.tar.gz to C:\\Users\\totmi\\.deeppavlov\\models\\ner_rus_bert_torch_new.tar.gz\n",
      "100%|██████████| 1.44G/1.44G [02:21<00:00, 10.2MB/s] \n",
      "2024-04-04 18:57:48.567 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting C:\\Users\\totmi\\.deeppavlov\\models\\ner_rus_bert_torch_new.tar.gz archive into C:\\Users\\totmi\\.deeppavlov\\models\\ner_rus_bert_torch\n",
      "C:\\Users\\totmi\\anaconda\\envs\\Diplom\\Lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "\n",
    "config_path = configs.ner.ner_rus_bert\n",
    "\n",
    "ner = build_model(config_path, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800000</td>\n",
       "      <td>Самый низкий показатель - среди жителей Японии...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800001</td>\n",
       "      <td>В самих США положительно ответили более 20 про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800002</td>\n",
       "      <td>Аналитики MPAA считают, что распространение пи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800003</td>\n",
       "      <td>При недостаточно высокой скорости соединения с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800004</td>\n",
       "      <td>Лидерство Южной Кореи в опросе обусловлено име...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  800000  Самый низкий показатель - среди жителей Японии...\n",
       "1  800001  В самих США положительно ответили более 20 про...\n",
       "2  800002  Аналитики MPAA считают, что распространение пи...\n",
       "3  800003  При недостаточно высокой скорости соединения с...\n",
       "4  800004  Лидерство Южной Кореи в опросе обусловлено име..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train_Lenta.csv', encoding='utf-8-sig', sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      1009468\n",
       "text    1009467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена пропущенных значений или значений других типов на пустые строки\n",
    "data['text'] = data['text'].fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 1009468/1009468 [2:39:43<00:00, 105.33it/s] \n"
     ]
    }
   ],
   "source": [
    "# Очистка текста от лишних символов\n",
    "data['text'] = data['text'].str.strip()\n",
    "\n",
    "# Применение модели NER к текстам из колонки 'text' и сохранение результатов в новую колонку 'tag'\n",
    "tags_list = []\n",
    "for sentence in tqdm(data['text'], desc=\"Processing sentences\"):\n",
    "    if isinstance(sentence, str) and sentence.strip():  # Проверяем, является ли значение текстом и не пустым\n",
    "        tokens, tags = ner([sentence])\n",
    "        tags_list.append(tags[0])\n",
    "    else:\n",
    "        tags_list.append([])  # Добавляем пустой список тегов\n",
    "\n",
    "data['tag'] = tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение обновленных данных в новый CSV-файл\n",
    "data.to_csv('Train_Lenta_NER.csv', encoding='utf-8-sig', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800000</td>\n",
       "      <td>Самый низкий показатель - среди жителей Японии...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800001</td>\n",
       "      <td>В самих США положительно ответили более 20 про...</td>\n",
       "      <td>['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800002</td>\n",
       "      <td>Аналитики MPAA считают, что распространение пи...</td>\n",
       "      <td>['O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800003</td>\n",
       "      <td>При недостаточно высокой скорости соединения с...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800004</td>\n",
       "      <td>Лидерство Южной Кореи в опросе обусловлено име...</td>\n",
       "      <td>['O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  800000  Самый низкий показатель - среди жителей Японии...   \n",
       "1  800001  В самих США положительно ответили более 20 про...   \n",
       "2  800002  Аналитики MPAA считают, что распространение пи...   \n",
       "3  800003  При недостаточно высокой скорости соединения с...   \n",
       "4  800004  Лидерство Южной Кореи в опросе обусловлено име...   \n",
       "\n",
       "                                                 tag  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', '...  \n",
       "1  ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', '...  \n",
       "2  ['O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4  ['O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train_Lenta_NER.csv', encoding='utf-8-sig', sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5MTL(torch.nn.Module):\n",
    "    def __init__(self, model_params: dict, task_type: str) -> None:\n",
    "        super(T5MTL, self).__init__()\n",
    "        self.task_type = task_type\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "        self.encoder = T5Model.from_pretrained(model_params[\"MODEL\"]).to(self.device)\n",
    "        self.decoder = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"]).to(self.device)\n",
    "        self.classifier = torch.nn.Linear(self.encoder.config.d_model, model_params[\"NUM_CLASSES\"]).to(self.device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, decoder_input_ids=None, labels=None):\n",
    "        # Encoding phase\n",
    "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        encoder_last_hidden_state = encoder_outputs.last_hidden_state\n",
    "\n",
    "        if self.task_type in ['paraphrase_task', 'qg_task', 'sum_task', 'titlegen_task']:\n",
    "            # Decoding phase for generation\n",
    "            if decoder_input_ids is not None:\n",
    "                outputs = self.decoder(input_ids=decoder_input_ids, encoder_hidden_states=encoder_last_hidden_state, labels=labels)\n",
    "            else:\n",
    "                outputs = self.decoder.generate(input_ids=None, encoder_hidden_states=encoder_last_hidden_state)\n",
    "        elif self.task_type in ['ner_task', 'sts_task', 'nli_task', 'sentiment_task']:\n",
    "            # Classification phase\n",
    "            outputs = self.classify(encoder_last_hidden_state)\n",
    "\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
